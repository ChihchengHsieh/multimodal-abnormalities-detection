{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import utils.print as print_f\n",
    "from data.dataset import REFLACXWithBoundingBoxesDataset, ReflacxAllCXRDataset\n",
    "from utils.transforms import get_transform\n",
    "from collections import OrderedDict\n",
    "\n",
    "## Suppress the assignement warning from pandas.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from utils.engine import official_evaluate, official_train_one_epoch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from utils.save import  get_train_data\n",
    "from datetime import datetime\n",
    "import PIL\n",
    "from matplotlib.patches import Rectangle\n",
    "import os \n",
    "\n",
    "import pickle\n",
    "from utils.engine import map_target_to_device\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "XAMI_MIMIC_PATH = \"D:\\XAMI-MIMIC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be using cuda\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = 'cuda' if use_gpu else 'cpu'\n",
    "print(f\"Will be using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cols = [\n",
    "    \"Enlarged cardiac silhouette\",\n",
    "    \"Atelectasis\",\n",
    "    \"Pleural abnormality\",\n",
    "    \"Consolidation\",\n",
    "    \"Pulmonary edema\",\n",
    "    #  'Groundglass opacity', # 6th disease.\n",
    "]\n",
    "\n",
    "train_dataset = REFLACXWithBoundingBoxesDataset(\n",
    "    XAMI_MIMIC_PATH=XAMI_MIMIC_PATH,\n",
    "    labels_cols=labels_cols,\n",
    "    split_str=\"train\",\n",
    "    transforms=get_transform(train=True),\n",
    ")\n",
    "\n",
    "val_dataset = REFLACXWithBoundingBoxesDataset(\n",
    "    XAMI_MIMIC_PATH=XAMI_MIMIC_PATH,\n",
    "    labels_cols=labels_cols,\n",
    "    split_str=\"val\",\n",
    "    transforms=get_transform(train=False),\n",
    ")\n",
    "\n",
    "test_dataset = REFLACXWithBoundingBoxesDataset(\n",
    "    XAMI_MIMIC_PATH=XAMI_MIMIC_PATH,\n",
    "    labels_cols=labels_cols,\n",
    "    split_str=\"test\",\n",
    "    transforms=get_transform(train=False),\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=REFLACXWithBoundingBoxesDataset.collate_fn,\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=REFLACXWithBoundingBoxesDataset.collate_fn,\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=REFLACXWithBoundingBoxesDataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5608, 0.5608, 0.5569,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5569, 0.5647, 0.5647,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5490, 0.5569, 0.5608,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.7686, 0.7686, 0.7647,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7608, 0.7647, 0.7608,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7529, 0.7569, 0.7569,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[0.5608, 0.5608, 0.5569,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5569, 0.5647, 0.5647,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5490, 0.5569, 0.5608,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.7686, 0.7686, 0.7647,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7608, 0.7647, 0.7608,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7529, 0.7569, 0.7569,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[0.5608, 0.5608, 0.5569,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5569, 0.5647, 0.5647,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5490, 0.5569, 0.5608,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.7686, 0.7686, 0.7647,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7608, 0.7647, 0.7608,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7529, 0.7569, 0.7569,  ..., 1.0000, 1.0000, 1.0000]]]),\n",
       " {'boxes': tensor([[ 734., 1204., 2211., 2175.]], dtype=torch.float64),\n",
       "  'labels': tensor([1]),\n",
       "  'image_id': tensor([0]),\n",
       "  'area': tensor([1434167.], dtype=torch.float64),\n",
       "  'iscrowd': tensor([0]),\n",
       "  'dicom_id': '34cedb74-d0996b40-6d218312-a9174bea-d48dc033',\n",
       "  'image_path': 'D:\\\\XAMI-MIMIC\\\\patient_18111516\\\\CXR-JPG\\\\s55032240\\\\34cedb74-d0996b40-6d218312-a9174bea-d48dc033.jpg'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.dataset import PennFudanDataset\n",
    "\n",
    "# train_dataset = PennFudanDataset('PennFudanPed', get_transform(train=True))\n",
    "# test_dataset = PennFudanDataset('PennFudanPed', get_transform(train=False))\n",
    "\n",
    "# indices = torch.randperm(len(train_dataset)).tolist()\n",
    "# dataset = torch.utils.data.Subset(train_dataset, indices[:-50])\n",
    "# dataset_test = torch.utils.data.Subset(test_dataset, indices[-50:])\n",
    "\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(\n",
    "#     dataset, batch_size=4, shuffle=True,\n",
    "#     collate_fn=REFLACXWithBoundingBoxesDataset.collate_fn)\n",
    "\n",
    "# test_dataloader = torch.utils.data.DataLoader(\n",
    "#     dataset_test, batch_size=4, shuffle=False,\n",
    "#     collate_fn=REFLACXWithBoundingBoxesDataset.collate_fn)\n",
    "\n",
    "# # val_dataloader = test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(\n",
    "        pretrained=True,\n",
    "        rpn_nms_thresh=0.5,\n",
    "        box_detections_per_img=10,\n",
    "        box_nms_thresh=0.2,\n",
    "    )\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask, hidden_layer, num_classes\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu4): ReLU(inplace=True)\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "# trainable_backbone_layers = torchvision.models.detection.backbone_utils._validate_trainable_layers(\n",
    "#     True, None, 5, 3\n",
    "# )\n",
    "# backbone = torchvision.models.detection.backbone_utils.resnet_fpn_backbone(\n",
    "#     \"resnet50\", pretrained=True, trainable_layers=trainable_backbone_layers\n",
    "# )\n",
    "# backbone.out_channels = 256\n",
    "\n",
    "\n",
    "######################## For MobileNet backbone ########################\n",
    "# from torchvision.models.detection.faster_rcnn import AnchorGenerator\n",
    "# backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
    "# backbone.out_channels = 1280\n",
    "\n",
    "# model = FasterRCNN(\n",
    "#     backbone,\n",
    "#     num_classes=len(train_dataset.labels_cols) + 1,\n",
    "#     rpn_anchor_generator=None,\n",
    "#     box_roi_pool=None,\n",
    "# )\n",
    "\n",
    "# anchor_generator = AnchorGenerator(\n",
    "#     sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),)\n",
    "# )\n",
    "# roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "#     featmap_names=[\"0\"], output_size=7, sampling_ratio=2\n",
    "# )\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# ResNet (Smaller model.)\n",
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "#     pretrained_backbone=True, num_classes=len(train_dataset.labels_cols) + 1,\n",
    "# )\n",
    "\n",
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "#     pretrained_backbone=True, num_classes=len(train_dataset.labels_cols) + 1,\n",
    "# )\n",
    "\n",
    "# testing with PennFudanDataset\n",
    "\n",
    "# Trainable fasterrcnn\n",
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "#     # pretrained_backbone=True, num_classes=2,\n",
    "#     pretrained=True,\n",
    "#     # num_classes=2,\n",
    "#     rpn_nms_thresh=0.5,\n",
    "#     box_detections_per_img=10,\n",
    "#     box_nms_thresh=0.2,\n",
    "# )\n",
    "\n",
    "# model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "# model = get_model_instance_segmentation(len(train_dataset.labels_cols) + 1)\n",
    "\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(\n",
    "        pretrained=True,\n",
    "        rpn_nms_thresh=0.5,\n",
    "        box_detections_per_img=10,\n",
    "        box_nms_thresh=0.2,\n",
    "    )\n",
    "    \n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 44,401,393\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model size: {sum([param.nelement()  for param in model.parameters()]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "lr_scheduler = None\n",
    "\n",
    "# construct an optimizer\n",
    "\n",
    "# optimizer = torch.optim.Adam(params, lr=0.05 ,weight_decay=0.0005)\n",
    "# lr_scheduler = None\n",
    "\n",
    "## Original Setting (Kinda work)\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                step_size=3,\n",
    "                                                gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_logers):\n",
    "\n",
    "    clear_output()\n",
    "    \n",
    "    train_data = [ get_train_data(loger) for loger in train_logers]\n",
    "\n",
    "    train_data_keys = train_data[0].keys()\n",
    "\n",
    "    fig, subplots  = plt.subplots(\n",
    "        len(train_data_keys), figsize=(10, 5* len(train_data_keys)), dpi=80, sharex=True)\n",
    "\n",
    "\n",
    "    fig.suptitle(f\"Training Losses\")\n",
    "\n",
    "    for i, k in enumerate(train_data_keys):\n",
    "        subplots[i].set_title(k)\n",
    "        subplots[i].plot([data[k] for data in train_data], marker='o', label=k, color='steelblue')\n",
    "        # subplots[i].legend(loc=\"upper left\")\n",
    "\n",
    "    subplots[-1].set_xlabel('Epoch')\n",
    "    plt.plot()\n",
    "    plt.pause(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transparent_cmap(cmap, N=255):\n",
    "    \"Copy colormap and set alpha values\"\n",
    "\n",
    "    t_cmap = cmap\n",
    "    t_cmap._init()\n",
    "    t_cmap._lut[:,-1] = np.linspace(0, 0.8, N+4)\n",
    "    return t_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_cmap = {\n",
    "    \"transparent\": {\n",
    "        \"Enlarged cardiac silhouette\": transparent_cmap(plt.cm.autumn),\n",
    "        \"Atelectasis\": transparent_cmap(plt.cm.Reds),\n",
    "        \"Pleural abnormality\": transparent_cmap(plt.cm.Oranges),\n",
    "        \"Consolidation\": transparent_cmap(plt.cm.Greens),\n",
    "        \"Pulmonary edema\": transparent_cmap(plt.cm.Blues),\n",
    "    },\n",
    "    \"solid\": {\n",
    "        {\n",
    "            \"Enlarged cardiac silhouette\": \"yellow\",\n",
    "            \"Atelectasis\": \"red\",\n",
    "            \"Pleural abnormality\": \"orange\",\n",
    "            \"Consolidation\": \"lightgreen\",\n",
    "            \"Pulmonary edema\": \"dodgerblue\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "transparent_disease_color_code_map = {\n",
    "    \"Enlarged cardiac silhouette\": transparent_cmap(plt.cm.autumn),\n",
    "    \"Atelectasis\": transparent_cmap(plt.cm.Reds),\n",
    "    \"Pleural abnormality\": transparent_cmap(plt.cm.Oranges),\n",
    "    \"Consolidation\": transparent_cmap(plt.cm.Greens),\n",
    "    \"Pulmonary edema\": transparent_cmap(plt.cm.Blues),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_color_code_map = {\n",
    "    'Enlarged cardiac silhouette': 'yellow',\n",
    "    'Atelectasis': 'red',\n",
    "    'Pleural abnormality': 'orange',\n",
    "    'Consolidation': 'lightgreen',\n",
    "    'Pulmonary edema': 'dodgerblue',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seg(target, pred, legend_elements, transparent_disease_color_code_map, seg_thres = 0):\n",
    "\n",
    "    fig, (gt_ax, pred_ax) = plt.subplots(1, 2, figsize=(20, 10), dpi=80, sharex=True)\n",
    "\n",
    "    fig.suptitle(target[\"image_path\"])\n",
    "\n",
    "    img = PIL.Image.open(target[\"image_path\"]).convert(\"RGB\")\n",
    "\n",
    "    gt_ax.imshow(img)\n",
    "    gt_ax.set_title(\"Ground Truth\")\n",
    "    pred_ax.imshow(img)\n",
    "    pred_ax.set_title(\"Predictions\")\n",
    "\n",
    "    fig.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "    for label, m in zip(\n",
    "        target[\"labels\"].detach().cpu().numpy(), target[\"masks\"].detach().cpu().numpy(),\n",
    "    ):\n",
    "        disease = train_dataset.label_index_to_disease(label)\n",
    "        mask_img = PIL.Image.fromarray(m * 255)\n",
    "        gt_ax.imshow(\n",
    "            mask_img,\n",
    "            transparent_disease_color_code_map[disease],\n",
    "            interpolation=\"none\",\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "    for label, m in zip(\n",
    "        pred[0][\"labels\"].detach().cpu().numpy(),\n",
    "        pred[0][\"masks\"].detach().cpu().numpy(),\n",
    "    ):\n",
    "        disease = train_dataset.label_index_to_disease(label)\n",
    "        mask = (m.squeeze() > seg_thres).astype(np.uint8)\n",
    "        mask_img = PIL.Image.fromarray(mask * 255)\n",
    "\n",
    "        pred_ax.imshow(\n",
    "            mask_img,\n",
    "            transparent_disease_color_code_map[disease],\n",
    "            interpolation=\"none\",\n",
    "            alpha=0.7\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox(target, pred, legend_elements, disease_color_code_map):\n",
    "\n",
    "    fig, (gt_ax, pred_ax) = plt.subplots(1, 2, figsize=(20, 10), dpi=80, sharex=True)\n",
    "\n",
    "    fig.suptitle(target[\"image_path\"])\n",
    "\n",
    "    fig.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "\n",
    "    img = PIL.Image.open(target[\"image_path\"]).convert(\"RGB\")\n",
    "\n",
    "    gt_ax.imshow(img)\n",
    "    gt_ax.set_title(f\"Ground Truth ({len(target['boxes'].detach().cpu().numpy())})\")\n",
    "    pred_ax.imshow(img)\n",
    "    pred_ax.set_title(f\"Predictions ({len(pred[0]['boxes'].detach().cpu().numpy())})\")\n",
    "\n",
    "    # load image\n",
    "    gt_recs = []\n",
    "    pred_recs = []\n",
    "    \n",
    "    for label, bbox in zip(pred[0]['labels'].detach().cpu().numpy(), pred[0]['boxes'].detach().cpu().numpy()):\n",
    "        disease = train_dataset.label_index_to_disease(label)\n",
    "        c = disease_color_code_map[disease]\n",
    "        pred_recs.append(Rectangle((bbox[0],bbox[1]), bbox[2] - bbox[0], bbox[3]-bbox[1], fill=False, color=c, linewidth=2))\n",
    "        pred_ax.text(bbox[0],bbox[1], disease,color=\"black\", backgroundcolor=c)\n",
    "\n",
    "    for rec in pred_recs:\n",
    "        pred_ax.add_patch(rec)\n",
    "\n",
    "    for label, bbox in zip(target['labels'].detach().cpu().numpy(),target['boxes'].detach().cpu().numpy()):\n",
    "        disease = train_dataset.label_index_to_disease(label)\n",
    "        c = disease_color_code_map[disease]\n",
    "        gt_recs.append(Rectangle((bbox[0],bbox[1]), bbox[2] - bbox[0], bbox[3]-bbox[1], fill=False, color=c, linewidth=2))\n",
    "        gt_ax.text(bbox[0],bbox[1], disease, color=\"black\",  backgroundcolor=c)\n",
    "\n",
    "    for rec in gt_recs:\n",
    "        gt_ax.add_patch(rec)\n",
    "    \n",
    "    plt.plot()\n",
    "    plt.pause(0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2, 3][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(\n",
    "    model,\n",
    "    dataset,\n",
    "    idx,\n",
    "    legend_elements,\n",
    "    disease_color_code_map,\n",
    "    transparent_disease_color_code_map,\n",
    "    seg_thres=0.5,\n",
    "):\n",
    "    image, target = dataset[idx]\n",
    "    target = map_target_to_device(target, device)\n",
    "    image = image.to(device)\n",
    "    pred = model([image])\n",
    "    plot_bbox(target, pred, legend_elements, disease_color_code_map)\n",
    "    # plot_seg(\n",
    "    #     target,\n",
    "    #     pred,\n",
    "    #     legend_elements,\n",
    "    #     transparent_disease_color_code_map,\n",
    "    #     seg_thres=seg_thres,\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike8\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28228/2048406852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     train_loger = official_train_one_epoch(\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\utils\\engine.py\u001b[0m in \u001b[0;36mofficial_train_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmap_target_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mloss_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m             \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatched_idxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_training_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py\u001b[0m in \u001b[0;36mselect_training_samples\u001b[1;34m(self, proposals, targets)\u001b[0m\n\u001b[0;32m    631\u001b[0m                                 ):\n\u001b[0;32m    632\u001b[0m         \u001b[1;31m# type: (...) -> Tuple[List[Tensor], List[Tensor], List[Tensor], List[Tensor]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproposals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py\u001b[0m in \u001b[0;36mcheck_targets\u001b[1;34m(self, targets)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"labels\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"masks\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     def select_training_samples(self,\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "train_logers = []\n",
    "val_evaluators = []\n",
    "\n",
    "start_t = datetime.now()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    model.train()\n",
    "    \n",
    "    train_loger = official_train_one_epoch(\n",
    "        model, optimizer, train_dataloader, device, epoch, print_freq=10\n",
    "    )\n",
    "    train_logers.append(train_loger)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    plot_loss(train_logers)\n",
    "    plot_result(model, train_dataset, 0, legend_elements, disease_color_code_map, transparent_disease_color_code_map, seg_thres=0.5)\n",
    "    plot_result(model, train_dataset, 45, legend_elements, disease_color_code_map, transparent_disease_color_code_map, seg_thres=0.5)\n",
    "    plot_result(model, train_dataset, 88, legend_elements, disease_color_code_map, transparent_disease_color_code_map, seg_thres=0.5)\n",
    "\n",
    "    # update the learning rate\n",
    "    if not lr_scheduler is None:\n",
    "        lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    val_evaluator = official_evaluate(model, val_dataloader, device=device)\n",
    "    val_evaluators.append(val_evaluator)\n",
    "\n",
    "end_t = datetime.now()\n",
    "\n",
    "sec_took = (end_t - start_t).seconds\n",
    "\n",
    "print_f.print_title(\n",
    "    f\"| Training Done, start testing! | Training time: [{sec_took}] seconds, Avg time / Epoch: [{sec_took/num_epochs}] seconds\"\n",
    ")\n",
    "\n",
    "test_evaluator = official_evaluate(model, test_dataloader, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_string_ha(a, b,c=\"Okay\"):\n",
    "    return f\"{a}dsadasd{b}dasd{c}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hahahadsadasdhellodasdOkay'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_string_ha(*(\"hahaha\", \"hello\", \"word\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n"
     ]
    }
   ],
   "source": [
    "test_evaluator.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_record = OrderedDict({\n",
    "    \"train_data\": [ get_train_data(loger) for loger in train_logers],\n",
    "    \"val_evaluators\" : val_evaluators,\n",
    "    \"test_evaluator\": test_evaluator,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinial_cond = \"Without\"\n",
    "current_time_string = datetime.now().strftime(\"%m-%d-%Y %H-%M-%S\")\n",
    "final_model_path =  f\"epoch{epoch}_{clinial_cond}Clincal_{current_time_string}\".replace(\":\", \"_\").replace(\".\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved: epoch9_WithoutClincal_03-10-2022 19-00-48\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), os.path.join(\n",
    "    os.path.join('trained_models', final_model_path)\n",
    "))\n",
    "\n",
    "print(f\"Model has been saved: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(\"training_records\", f\"{final_model_path}.pkl\"), \"wb\",\n",
    ") as training_record_f:\n",
    "    pickle.dump(training_record, training_record_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch9_WithoutClincal_03-10-2022 05-35-31 => all relfacx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a402e4e4296f2d4bed1c089fb7c7e828933dcbfe50698b381e393c052eea855"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
