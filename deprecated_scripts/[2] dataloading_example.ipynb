{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "This notebook will build a Pytorch dataset that load the following data as the input of our models. Since the task we want the model to perform is object detection. Therefore, we want our model to get these input data for erach instance:\n",
    "\n",
    "- CXR image\n",
    "- Clinical data\n",
    "- Bouding boxes coordinate with its label class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"reflacx_with_clinical.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {XAMI_MIMIC_PATH}\\patient_18111516\\REFLACX\\P10...\n",
       "1       {XAMI_MIMIC_PATH}\\patient_18111516\\REFLACX\\P10...\n",
       "2       {XAMI_MIMIC_PATH}\\patient_18111516\\REFLACX\\P10...\n",
       "3       {XAMI_MIMIC_PATH}\\patient_18111516\\REFLACX\\P10...\n",
       "4       {XAMI_MIMIC_PATH}\\patient_18111516\\REFLACX\\P10...\n",
       "                              ...                        \n",
       "3020    {XAMI_MIMIC_PATH}\\patient_19875621\\REFLACX\\P30...\n",
       "3023    {XAMI_MIMIC_PATH}\\patient_19884194\\REFLACX\\P30...\n",
       "3027    {XAMI_MIMIC_PATH}\\patient_19906407\\REFLACX\\P30...\n",
       "3028    {XAMI_MIMIC_PATH}\\patient_19907884\\REFLACX\\P30...\n",
       "3039    {XAMI_MIMIC_PATH}\\patient_19957626\\REFLACX\\P30...\n",
       "Name: anomaly_location_ellipses_path, Length: 670, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XAMI_MIMIC_PATH = \"D:\\XAMI-MIMIC\"\n",
    "\n",
    "df['image_path'].apply(lambda x: x.replace(\"{XAMI_MIMIC_PATH}\", XAMI_MIMIC_PATH))\n",
    "\n",
    "df['anomaly_location_ellipses_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.transforms as T\n",
    "\n",
    "# import torchvision.transforms as torch_transform\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class REFLACXWithClinicalAndBoundingBoxDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        XAMI_MIMIC_PATH,\n",
    "        device,\n",
    "        transforms=None,\n",
    "        image_size=224,\n",
    "        clinical_cols=[\n",
    "            \"age\",\n",
    "            \"gender\",\n",
    "            \"temperature\",\n",
    "            \"heartrate\",\n",
    "            \"resprate\",\n",
    "            \"o2sat\",\n",
    "            \"sbp\",\n",
    "            \"dbp\",\n",
    "            \"pain\",\n",
    "            \"acuity\",\n",
    "        ],\n",
    "        clinical_numerical_cols=[\n",
    "            \"age\",\n",
    "            \"temperature\",\n",
    "            \"heartrate\",\n",
    "            \"resprate\",\n",
    "            \"o2sat\",\n",
    "            \"sbp\",\n",
    "            \"dbp\",\n",
    "            \"pain\",\n",
    "            \"acuity\",\n",
    "        ],\n",
    "        clinical_categorical_cols=[\"gender\"],\n",
    "        labels_cols=[\n",
    "            \"Enlarged cardiac silhouette\",\n",
    "            \"Atelectasis\",\n",
    "            \"Pleural abnormality\",\n",
    "            \"Consolidation\",\n",
    "            \"Pulmonary edema\",\n",
    "            #  'Groundglass opacity', # 6th disease.\n",
    "        ],\n",
    "        all_disease_cols=[\n",
    "            \"Airway wall thickening\",\n",
    "            \"Atelectasis\",\n",
    "            \"Consolidation\",\n",
    "            \"Enlarged cardiac silhouette\",\n",
    "            \"Fibrosis\",\n",
    "            \"Groundglass opacity\",\n",
    "            \"Pneumothorax\",\n",
    "            \"Pulmonary edema\",\n",
    "            \"Wide mediastinum\",\n",
    "            \"Abnormal mediastinal contour\",\n",
    "            \"Acute fracture\",\n",
    "            \"Enlarged hilum\",\n",
    "            \"Hiatal hernia\",\n",
    "            \"High lung volume / emphysema\",\n",
    "            \"Interstitial lung disease\",\n",
    "            \"Lung nodule or mass\",\n",
    "            \"Pleural abnormality\",\n",
    "        ],\n",
    "        repetitive_label_map={\n",
    "            \"Airway wall thickening\": [\"Airway wall thickening\"],\n",
    "            \"Atelectasis\": [\"Atelectasis\"],\n",
    "            \"Consolidation\": [\"Consolidation\"],\n",
    "            \"Enlarged cardiac silhouette\": [\"Enlarged cardiac silhouette\"],\n",
    "            \"Fibrosis\": [\"Fibrosis\"],\n",
    "            \"Groundglass opacity\": [\"Groundglass opacity\"],\n",
    "            \"Pneumothorax\": [\"Pneumothorax\"],\n",
    "            \"Pulmonary edema\": [\"Pulmonary edema\"],\n",
    "            \"Quality issue\": [\"Quality issue\"],\n",
    "            \"Support devices\": [\"Support devices\"],\n",
    "            \"Wide mediastinum\": [\"Wide mediastinum\"],\n",
    "            \"Abnormal mediastinal contour\": [\"Abnormal mediastinal contour\"],\n",
    "            \"Acute fracture\": [\"Acute fracture\"],\n",
    "            \"Enlarged hilum\": [\"Enlarged hilum\"],\n",
    "            \"Hiatal hernia\": [\"Hiatal hernia\"],\n",
    "            \"High lung volume / emphysema\": [\n",
    "                \"High lung volume / emphysema\",\n",
    "                \"Emphysema\",\n",
    "            ],\n",
    "            \"Interstitial lung disease\": [\"Interstitial lung disease\"],\n",
    "            \"Lung nodule or mass\": [\"Lung nodule or mass\", \"Mass\", \"Nodule\"],\n",
    "            \"Pleural abnormality\": [\n",
    "                \"Pleural abnormality\",\n",
    "                \"Pleural thickening\",\n",
    "                \"Pleural effusion\",\n",
    "            ],\n",
    "        },\n",
    "        box_fix_cols=[\"xmin\", \"ymin\", \"xmax\", \"ymax\", \"certainty\"],\n",
    "        box_coord_cols = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"],\n",
    "        path_cols = ['image_path', 'anomaly_location_ellipses_path'],\n",
    "    ):\n",
    "        super(REFLACXWithClinicalAndBoundingBoxDataset, self).__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.df = pd.read_csv(\"reflacx_with_clinical.csv\", index_col=0)\n",
    "        \n",
    "        for p_col in path_cols:\n",
    "            self.df[p_col] = self.df[p_col].apply(lambda x: x.replace(\"{XAMI_MIMIC_PATH}\", XAMI_MIMIC_PATH))\n",
    "\n",
    "        self.clinical_cols = clinical_cols\n",
    "        self.clinical_numerical_cols = clinical_numerical_cols\n",
    "        self.clinical_categorical_cols = clinical_categorical_cols\n",
    "        self.labels_cols = labels_cols\n",
    "        self.all_disease_cols = all_disease_cols\n",
    "        self.repetitive_label_map  = repetitive_label_map\n",
    "        self.box_fix_cols = box_fix_cols\n",
    "        self.box_coord_cols = box_coord_cols\n",
    "        self.device = device\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.encoders_map = {}\n",
    "\n",
    "        self.preprocess_clinical_df()\n",
    "        self.preprocess_label()\n",
    "        # self.get_weights()\n",
    "\n",
    "    def preprocess_clinical_df(self,):\n",
    "        self.encoders_map = {}\n",
    "\n",
    "        # encode the categorical cols.\n",
    "        for col in self.clinical_categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            self.df[col] = le.fit_transform(self.df[col])\n",
    "            self.encoders_map[col] = le\n",
    "\n",
    "    def preprocess_label(self,):\n",
    "        self.df[self.all_disease_cols] = self.df[self.all_disease_cols].gt(0)\n",
    "\n",
    "    def load_image_array(self, image_path):\n",
    "        return np.asarray(Image.open(image_path))\n",
    "\n",
    "    def plot_image_from_array(self, image_array):\n",
    "        im = Image.fromarray(image_array)\n",
    "        im.show()\n",
    "\n",
    "    def disease_to_idx(self, disease):\n",
    "\n",
    "        if not disease in self.labels_cols:\n",
    "            raise Exception(\"This disease is not the label.\") \n",
    "\n",
    "        return self.labels_cols.index(disease) + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "    def generate_boxes_df(\n",
    "        self, \n",
    "        ellipse_df,\n",
    "    ):\n",
    "        boxes_df = ellipse_df[self.box_fix_cols]\n",
    "\n",
    "        # relabel it.\n",
    "        for k in self.repetitive_label_map.keys():\n",
    "            boxes_df[k] = ellipse_df[\n",
    "                [l for l in self.repetitive_label_map[k] if l in ellipse_df.columns]\n",
    "            ].any(axis=1)\n",
    "\n",
    "        # filtering out the diseases not in the label_cols\n",
    "\n",
    "        boxes_df = boxes_df[boxes_df[self.labels_cols].any(axis=1)]\n",
    "\n",
    "        boxes_df['label'] = boxes_df[self.labels_cols].idxmax(axis= 1)\n",
    "\n",
    "        boxes_df = boxes_df[self.box_fix_cols + ['label']]\n",
    "\n",
    "        return boxes_df\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        return tuple(zip(*batch))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # find the df\n",
    "        data = self.df.iloc[idx]\n",
    "\n",
    "        img = Image.open(data[\"image_path\"]).convert(\"RGB\") \n",
    "\n",
    "        ## Prepare clinical data here.\n",
    "        clinical_numerical_input = torch.tensor(\n",
    "            np.array(data[self.clinical_numerical_cols], dtype=float)\n",
    "        ).float()\n",
    "\n",
    "        clinical_categorical_input =  torch.tensor(np.array(data[self.clinical_categorical_cols], dtype=int))\n",
    "\n",
    "        boxes_df = self.generate_boxes_df(pd.read_csv(data['anomaly_location_ellipses_path']))\n",
    "        boxes = torch.tensor(np.array(boxes_df[self.box_coord_cols]))\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        labels = torch.tensor(np.array(boxes_df['label'].apply(lambda l: self.disease_to_idx(l))), dtype=torch.int64)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "\n",
    "        num_objs = boxes.shape[0]\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, clinical_numerical_input, clinical_categorical_input, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be using cuda\n"
     ]
    }
   ],
   "source": [
    "# checking if the GPU is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = 'cuda' if use_gpu else 'cpu'\n",
    "print(f\"Will be using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "XAMI_MIMIC_PATH = \"D:\\XAMI-MIMIC\"\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "dataset = REFLACXWithClinicalAndBoundingBoxDataset(XAMI_MIMIC_PATH, device, transforms=get_transform(train=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img, example_clinical_num, example_clinical_cat, example_target = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3056, 2544])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_clinical_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_clinical_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[ 734, 1204, 2211, 2175]]),\n",
       " 'labels': tensor([1]),\n",
       " 'image_id': tensor([0]),\n",
       " 'area': tensor([1434167]),\n",
       " 'iscrowd': tensor([0])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target['boxes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target['iscrowd'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a402e4e4296f2d4bed1c089fb7c7e828933dcbfe50698b381e393c052eea855"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
