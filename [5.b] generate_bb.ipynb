{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, torch\n",
    "import os \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from models.load import TrainedModels\n",
    "\n",
    "from utils.eval import save_iou_results\n",
    "from utils.engine import xami_evaluate, get_iou_types\n",
    "from utils.plot import plot_losses, plot_train_val_ap_ars\n",
    "from models.load import get_trained_model\n",
    "from utils.coco_eval import get_eval_params_dict\n",
    "from data.datasets import  OurRadiologsitsDataset, collate_fn\n",
    "from our_radiologist.load import get_anns\n",
    "from utils.train import get_optimiser, get_lr_scheduler, print_params_setup\n",
    "from utils.coco_utils import get_cocos, get_coco_api_from_dataset\n",
    "from utils.eval import get_ar_ap\n",
    "from utils.print import print_title\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "from data.constants import XAMI_MIMIC_PATH, DEFAULT_REFLACX_LABEL_COLS\n",
    "from utils.constants import full_iou_thrs, iou_thrs_5to95\n",
    "from data.load  import seed_worker, get_dataloader_g\n",
    "import PIL\n",
    "from matplotlib.figure import Figure\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm import trange\n",
    "\n",
    "from typing import Callable, Dict, List, Union, Tuple\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import colors\n",
    "from utils.pred import pred_thrs_check\n",
    "from utils.save import get_data_from_metric_logger\n",
    "from data.datasets import ReflacxDataset, collate_fn\n",
    "from utils.detect_utils import MetricLogger\n",
    "from utils.coco_eval import CocoEvaluator, external_summarize\n",
    "from utils.plot import DISEASE_CMAP, get_legend_elements\n",
    "from models.train import TrainingInfo\n",
    "from models.build import create_model_from_setup\n",
    "\n",
    "\n",
    "## Suppress the assignement warning from pandas.\n",
    "pd.options.mode.chained_assignment = None  # default='warn\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "# plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n"
     ]
    }
   ],
   "source": [
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TrainedModels(Enum):\n",
    "    \n",
    "    CXR_Clinical_ap = \"val_ar_0_9381_ap_0_6945_test_ar_0_8224_ap_0_6378_epoch20_WithClincal_05-16-2022 18-13-10_CXR+Clinical\"\n",
    "    CXR_Clinical_final = \"val_ar_0_9556_ap_0_6776_test_ar_0_7849_ap_0_6534_epoch71_WithClincal_05-16-2022 19-38-03_CXR+Clinical\"\n",
    "\n",
    "    CXR_ap = \"val_ar_0_7518_ap_0_5042_test_ar_0_5388_ap_0_3255_epoch22_WithoutClincal_05-16-2022 20-18-25_CXR\"\n",
    "    CXR_final = \"val_ar_0_5966_ap_0_4046_test_ar_0_5388_ap_0_3893_epoch54_WithoutClincal_05-16-2022 21-10-18_CXR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_map = {\n",
    "    # TrainedModels.with_clinical: \"with_clinical_best\",\n",
    "    # TrainedModels.with_clinical_final: \"with_clinical_final\",\n",
    "    TrainedModels.CXR_final: \"CXR\",\n",
    "    # TrainedModels.without_clinical_final: \"without_clinical_final\",\n",
    "    TrainedModels.CXR_Clinical_final: \"CXR + Clinical\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load custom model\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "Found optimizer for this model.\n",
      "Using SGD as optimizer with lr=0.001\n",
      "Load custom model\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "Found optimizer for this model.\n",
      "Using SGD as optimizer with lr=0.001\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "train_infos = []\n",
    "\n",
    "for select_model in [\n",
    "    TrainedModels.CXR_final,\n",
    "    TrainedModels.CXR_Clinical_final,\n",
    "]:\n",
    "\n",
    "    model, train_info, _ = get_trained_model(\n",
    "        select_model,\n",
    "        DEFAULT_REFLACX_LABEL_COLS,\n",
    "        device,\n",
    "        rpn_nms_thresh=0.3,\n",
    "        box_detections_per_img=10,\n",
    "        box_nms_thresh=0.2,\n",
    "        rpn_score_thresh=0.0,\n",
    "        box_score_thresh=0.05,\n",
    "    )\n",
    "    model.eval()\n",
    "    train_info.name = naming_map[select_model]\n",
    "    models.append(model)\n",
    "    train_infos.append(train_info)\n",
    "\n",
    "    # without_clinical_model, without_clinical_train_info, _ = get_trained_model(\n",
    "    #     TrainedModels.without_clinical,\n",
    "    #     DEFAULT_REFLACX_LABEL_COLS,\n",
    "    #     device,\n",
    "    #     rpn_nms_thresh=0.3,\n",
    "    #     box_detections_per_img=10,\n",
    "    #     box_nms_thresh=0.2,\n",
    "    #     rpn_score_thresh=0.0,\n",
    "    #     box_score_thresh=0.05,\n",
    "    # )\n",
    "    # without_clinical_model.eval()\n",
    "\n",
    "    # with_clinical_model, with_clinical_train_info, _ = get_trained_model(\n",
    "    #         TrainedModels.with_clinical,\n",
    "    #         DEFAULT_REFLACX_LABEL_COLS,\n",
    "    #         device,\n",
    "    #         rpn_nms_thresh=0.3,\n",
    "    #         box_detections_per_img=10,\n",
    "    #         box_nms_thresh=0.2,\n",
    "    #         rpn_score_thresh=0.0,\n",
    "    #         box_score_thresh=0.05,\n",
    "    # )\n",
    "    # with_clinical_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.transforms import get_transform\n",
    "\n",
    "dataset_params_dict = {\n",
    "    \"XAMI_MIMIC_PATH\": XAMI_MIMIC_PATH,\n",
    "    \"with_clinical\": True,\n",
    "    \"dataset_mode\": 'unified',\n",
    "    \"bbox_to_mask\": False,\n",
    "    \"labels_cols\": DEFAULT_REFLACX_LABEL_COLS,\n",
    "}\n",
    "\n",
    "\n",
    "detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "    dataset_params_dict=dataset_params_dict,\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_model, clinical_train_info, _ = get_trained_model(\n",
    "    TrainedModels.CXR_Clinical_final,\n",
    "    DEFAULT_REFLACX_LABEL_COLS,\n",
    "    device,\n",
    "    rpn_nms_thresh=0.3,\n",
    "    box_detections_per_img=10,\n",
    "    box_nms_thresh=0.2,\n",
    "    rpn_score_thresh=0.0,\n",
    "    box_score_thresh=0.05,\n",
    ")\n",
    "\n",
    "clinical_model.to(device)\n",
    "clinical_model.eval()\n",
    "\n",
    "\n",
    "n_threads = torch.get_num_threads()\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "data = next(iter(test_dataloader))\n",
    "data = test_dataloader.dataset.prepare_input_from_data(data, device)\n",
    "loss_dict, outputs = clinical_model(*data[:-1])\n",
    "\n",
    "torch.set_num_threads(n_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_info in train_infos:\n",
    "#     print(train_info)\n",
    "#     model_setup = train_info.model_setup\n",
    "#     model = create_model_from_setup(\n",
    "#         DEFAULT_REFLACX_LABEL_COLS,\n",
    "#         model_setup,\n",
    "#         rpn_nms_thresh=0.3,\n",
    "#         box_detections_per_img=10,\n",
    "#         box_nms_thresh=0.2,\n",
    "#         rpn_score_thresh=0.0,\n",
    "#         box_score_thresh=0.05,\n",
    "#     )\n",
    "#     print_params_setup(model)\n",
    "#     plot_train_val_ap_ars(train_info.train_ap_ars, train_info.val_ap_ars)\n",
    "#     plot_losses(train_info.train_data, train_info.val_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_iobb = True\n",
    "# iou_thrs = np.array([0.5])\n",
    "# model = models[0]\n",
    "# model_setup = train_infos[0].model_setup\n",
    "\n",
    "# detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "#     dataset_params_dict=dataset_params_dict,\n",
    "# )\n",
    "\n",
    "# train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "#     train_dataset, val_dataset, test_dataset, batch_size=4,\n",
    "# )\n",
    "\n",
    "# train_coco, val_coco, test_coco = get_cocos(\n",
    "#     train_dataloader, val_dataloader, test_dataloader\n",
    "# )\n",
    "\n",
    "\n",
    "# eval_params_dict = get_eval_params_dict(\n",
    "#     detect_eval_dataset, iou_thrs=iou_thrs, use_iobb=use_iobb,\n",
    "# )\n",
    "\n",
    "# iou_types = get_iou_types(model, model_setup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_elements = get_legend_elements(DISEASE_CMAP[\"solid\"])\n",
    "\n",
    "g_table = None\n",
    "\n",
    "def plot_result_for_models(\n",
    "    models: nn.Module,\n",
    "    train_infos: List[TrainingInfo],\n",
    "    dataset: ReflacxDataset,\n",
    "    device: str,\n",
    "    idx: int,\n",
    "    legend_elements: List[Line2D],\n",
    "    disease_cmap=DISEASE_CMAP,\n",
    "    score_thres: Dict = None,\n",
    "    roi_head_thrs=None,\n",
    ") -> Tuple[Figure, Union[Figure, None]]:\n",
    "    # change all the model to eval mode.\n",
    "\n",
    "    ## retrieve the data, and transform them into input.\n",
    "\n",
    "    # this dataset has to be the one with clinical.\n",
    "    data = collate_fn([dataset[idx]])\n",
    "    data = dataset.prepare_input_from_data(data, device)\n",
    "    imgs, clinical_num, clinical_cat, targets = data\n",
    "\n",
    "    clinical_series = dataset.df.iloc[idx][dataset.clinical_cols]\n",
    "    clinical_series[\"gender\"] = dataset.encoders_map[\"gender\"].inverse_transform(\n",
    "        [clinical_series[\"gender\"]]\n",
    "    )[0]\n",
    "\n",
    "    ## Get the predictions from all the models.\n",
    "    preds = []\n",
    "    for train_info, model in zip(train_infos, models):\n",
    "        model.eval()\n",
    "        if roi_head_thrs:\n",
    "            model.roi_heads.score_thresh = roi_head_thrs\n",
    "        if train_info.model_setup.use_clinical:\n",
    "            _, pred = model(imgs, clinical_num, clinical_cat)\n",
    "        else:\n",
    "            _, pred = model(imgs)\n",
    "\n",
    "        if score_thres:\n",
    "            pred = pred_thrs_check(pred, dataset, score_thres, device)\n",
    "\n",
    "        preds.append(pred[0])\n",
    "    # return preds\n",
    "    return preds, targets\n",
    "\n",
    "    bb_fig = plot_bbox_for_models(\n",
    "        clinical_series,\n",
    "        targets[0],\n",
    "        preds,\n",
    "        train_infos,\n",
    "        dataset.label_idx_to_disease,\n",
    "        legend_elements,\n",
    "        disease_cmap[\"solid\"],\n",
    "    )\n",
    "\n",
    "    return bb_fig\n",
    "\n",
    "\n",
    "def plot_bbox_for_models(\n",
    "    clinical_series: pd.Series,\n",
    "    target: List[Dict],\n",
    "    preds: List[List[Dict]],\n",
    "    train_infos: List[TrainingInfo],\n",
    "    label_idx_to_disease: Callable[[int], str],\n",
    "    legend_elements: List[Line2D],\n",
    "    disease_color_code_map: Dict[str, str],\n",
    ") -> Figure:\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 3 + len(preds), figsize=((len(preds) + 3) * 10, 10), dpi=120, sharex=True\n",
    "    )\n",
    "\n",
    "    fig.suptitle(target[\"image_path\"])\n",
    "\n",
    "    fig.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "    img = PIL.Image.open(target[\"image_path\"]).convert(\"RGB\")\n",
    "\n",
    "    # show the image in every matrix.\n",
    "    for ax in axes[1:]:\n",
    "        ax.imshow(img)\n",
    "\n",
    "    # we plot the tabular data over here.\n",
    "    axes[0].set_title(f\"Clinical Data\")\n",
    "    table = axes[0].table(\n",
    "        cellText=[[v] for v in clinical_series.values],\n",
    "        rowLabels=clinical_series.index,\n",
    "        loc=\"center right\",\n",
    "        colWidths=[0.1, 0.1],\n",
    "    )\n",
    "    table.scale(2, 4)\n",
    "    table.set_fontsize(85)\n",
    "    axes[0].axis(\"off\")\n",
    "    # axes[0].axis(\"tight\")\n",
    "\n",
    "    # plot gt.\n",
    "    axes[1].set_title(f\"Original CXR\")\n",
    "\n",
    "    gt_ax_i = 2\n",
    "    axes[gt_ax_i].set_title(\n",
    "        f\"Ground Truth ({len(target['boxes'].detach().cpu().numpy())})\"\n",
    "    )\n",
    "\n",
    "    for label, bbox in zip(\n",
    "        target[\"labels\"].detach().cpu().numpy(), target[\"boxes\"].detach().cpu().numpy(),\n",
    "    ):\n",
    "        disease = label_idx_to_disease(label)\n",
    "        c = disease_color_code_map[disease]\n",
    "        axes[gt_ax_i].add_patch(\n",
    "            Rectangle(\n",
    "                (bbox[0], bbox[1]),\n",
    "                bbox[2] - bbox[0],\n",
    "                bbox[3] - bbox[1],\n",
    "                fill=False,\n",
    "                color=c,\n",
    "                linewidth=2,\n",
    "            )\n",
    "        )\n",
    "        axes[gt_ax_i].text(bbox[0], bbox[1], disease, color=\"black\", backgroundcolor=c)\n",
    "\n",
    "    # plot pred.\n",
    "    for i, pred in enumerate(preds):\n",
    "        ax = axes[i + 3]\n",
    "        ax.set_title(\n",
    "            f\"{train_infos[i].name} - Predictions ({len(pred['boxes'].detach().cpu().numpy())})\"\n",
    "        )\n",
    "\n",
    "        # for the predictions. generate the recs, and draw it on fig.\n",
    "        for label, bbox, score in zip(\n",
    "            pred[\"labels\"].detach().cpu().numpy(),\n",
    "            pred[\"boxes\"].detach().cpu().numpy(),\n",
    "            pred[\"scores\"].detach().cpu().numpy(),\n",
    "        ):\n",
    "            disease = label_idx_to_disease(label)\n",
    "            c = disease_color_code_map[disease]\n",
    "            ax.add_patch(\n",
    "                Rectangle(\n",
    "                    (bbox[0], bbox[1]),\n",
    "                    bbox[2] - bbox[0],\n",
    "                    bbox[3] - bbox[1],\n",
    "                    fill=False,\n",
    "                    color=c,\n",
    "                    linewidth=2,\n",
    "                )\n",
    "            )\n",
    "            ax.text(\n",
    "                bbox[0],\n",
    "                bbox[1],\n",
    "                f\"{disease} ({score:.2f})\",\n",
    "                color=\"black\",\n",
    "                backgroundcolor=c,\n",
    "            )\n",
    "\n",
    "    # plt.plot()\n",
    "    # plt.pause(0.01)\n",
    "\n",
    "    # fig.tight_layout()\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_result_for_models(\n",
    "#         models,\n",
    "#         train_infos,\n",
    "#         detect_eval_dataset,\n",
    "#         device,\n",
    "#         idx=0,\n",
    "#         legend_elements=legend_elements,\n",
    "#         disease_cmap=DISEASE_CMAP,\n",
    "#         roi_head_thrs=0.3,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "dataset = test_dataset\n",
    "# roi_head_thrs = 0.05\n",
    "# score_thres = None\n",
    "\n",
    "data = collate_fn([dataset[idx]])\n",
    "data = dataset.prepare_input_from_data(data, device)\n",
    "imgs, clinical_num, clinical_cat, targets = data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load custom model\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "Found optimizer for this model.\n",
      "Using SGD as optimizer with lr=0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultimodalMaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ConvNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(576, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (rpn): XAMIRegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(16, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(16, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): XAMIRoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): XAMITwoMLPHead(\n",
       "      (fc6): Sequential(\n",
       "        (0): Linear(in_features=784, out_features=32, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=False)\n",
       "      )\n",
       "      (fc7): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=32, out_features=6, bias=True)\n",
       "      (bbox_pred): Linear(in_features=32, out_features=24, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gender_emb_layer): Embedding(2, 23)\n",
       "  (clinical_expand_conv): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout2d(p=0, inplace=False)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout2d(p=0, inplace=False)\n",
       "    (8): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout2d(p=0, inplace=False)\n",
       "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Dropout2d(p=0, inplace=False)\n",
       "    (16): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): Dropout2d(p=0, inplace=False)\n",
       "    (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU()\n",
       "    (23): Dropout2d(p=0, inplace=False)\n",
       "    (24): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU()\n",
       "    (27): Dropout2d(p=0, inplace=False)\n",
       "    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU()\n",
       "    (31): Dropout2d(p=0, inplace=False)\n",
       "    (32): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (34): ReLU()\n",
       "    (35): Dropout2d(p=0, inplace=False)\n",
       "    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU()\n",
       "    (39): Dropout2d(p=0, inplace=False)\n",
       "    (40): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU()\n",
       "    (43): Dropout2d(p=0, inplace=False)\n",
       "    (44): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (45): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (46): ReLU()\n",
       "    (47): Dropout2d(p=0, inplace=False)\n",
       "    (48): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (50): ReLU()\n",
       "    (51): Dropout2d(p=0, inplace=False)\n",
       "    (52): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (53): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (54): ReLU()\n",
       "    (55): Dropout2d(p=0, inplace=False)\n",
       "    (56): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (57): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (58): ReLU()\n",
       "    (59): Dropout2d(p=0, inplace=False)\n",
       "    (60): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (61): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (clinical_convs): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout2d(p=0, inplace=False)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout2d(p=0, inplace=False)\n",
       "    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout2d(p=0, inplace=False)\n",
       "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Dropout2d(p=0, inplace=False)\n",
       "    (16): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fuse_convs): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout2d(p=0, inplace=False)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout2d(p=0, inplace=False)\n",
       "    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout2d(p=0, inplace=False)\n",
       "    (12): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Dropout2d(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
       "  'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)},\n",
       " {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
       "  'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)},\n",
       " {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
       "  'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)},\n",
       " {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
       "  'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, pred = clinical_model(imgs, clinical_num, clinical_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
       "  'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17336/3440216860.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclinical_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclinical_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# _, pred = model(*data[:-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# _, pred = model(*data[:-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "idx = 534\n",
    "dataset = detect_eval_dataset\n",
    "roi_head_thrs = 0.05\n",
    "score_thres = None\n",
    "\n",
    "data = collate_fn([dataset[idx]])\n",
    "data = dataset.prepare_input_from_data(data, device)\n",
    "imgs, clinical_num, clinical_cat, targets = data\n",
    "\n",
    "clinical_series = dataset.df.iloc[idx][dataset.clinical_cols]\n",
    "clinical_series[\"gender\"] = dataset.encoders_map[\"gender\"].inverse_transform(\n",
    "    [clinical_series[\"gender\"]]\n",
    ")[0]\n",
    "\n",
    "## Get the predictions from all the models.\n",
    "preds = []\n",
    "for train_info, model in zip(train_infos, models):\n",
    "    model.eval()\n",
    "    if roi_head_thrs:\n",
    "        model.roi_heads.score_thresh = roi_head_thrs\n",
    "    if train_info.model_setup.use_clinical:\n",
    "        _, pred = model(imgs, clinical_num, clinical_cat)\n",
    "        # _, pred = model(*data[:-1])\n",
    "        raise StopIteration()\n",
    "    else:\n",
    "        # _, pred = model(*data[:-1])\n",
    "        _, pred = model(imgs)\n",
    "\n",
    "\n",
    "    preds.append(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[534]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_eval_dataset.get_idxs_from_dicom_id(\"1c038d27-c6193e6a-d4588595-a78608bd-565e11fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_path': 'D:\\\\XAMI-MIMIC\\\\patient_19061282\\\\CXR-JPG\\\\s51863042\\\\1c038d27-c6193e6a-d4588595-a78608bd-565e11fa.jpg',\n",
       "  'dicom_id': '1c038d27-c6193e6a-d4588595-a78608bd-565e11fa',\n",
       "  'iscrowd': tensor([0, 0], device='cuda:0'),\n",
       "  'area': tensor([696619., 310596.], device='cuda:0', dtype=torch.float64),\n",
       "  'image_id': tensor([534], device='cuda:0'),\n",
       "  'labels': tensor([4, 3], device='cuda:0'),\n",
       "  'boxes': tensor([[ 400., 1176.,  981., 2375.],\n",
       "          [  99., 2160.,  642., 2732.]], device='cuda:0', dtype=torch.float64)}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[ 393.4535, 1746.0244, 2170.3828, 2847.0959],\n",
       "          [ 405.5574, 1394.8773,  868.5236, 2439.0625],\n",
       "          [ 393.4281, 1365.0924,  865.6730, 2468.5864]], device='cuda:0',\n",
       "         grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([1, 4, 5], device='cuda:0'),\n",
       "  'scores': tensor([0.8629, 0.7605, 0.1658], device='cuda:0', grad_fn=<IndexBackward0>)}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
       "  'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = plot_result_for_models(\n",
    "            models,\n",
    "            train_infos,\n",
    "            detect_eval_dataset,\n",
    "            device,\n",
    "            idx=0,\n",
    "            legend_elements=legend_elements,\n",
    "            disease_cmap=DISEASE_CMAP,\n",
    "            roi_head_thrs=0.05,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[ 938.9967, 1382.7239, 2530.7029, 2470.7102]], device='cuda:0',\n",
       "         grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([1], device='cuda:0'),\n",
       "  'scores': tensor([0.9209], device='cuda:0', grad_fn=<IndexBackward0>)},\n",
       " {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
       "  'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 72/590 [04:17<30:53,  3.58s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 93293568 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9080/606945432.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetect_eval_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         fig = plot_result_for_models(\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mtrain_infos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9080/3800271359.py\u001b[0m in \u001b[0;36mplot_result_for_models\u001b[1;34m(models, train_infos, dataset, device, idx, legend_elements, disease_cmap, score_thres, roi_head_thrs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# this dataset has to be the one with clinical.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_input_from_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclinical_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclinical_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\data\\datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"masks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mimg_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_clinical\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\data\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, image, target)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\data\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, image, target)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mike8\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 93293568 bytes."
     ]
    }
   ],
   "source": [
    "# iou_thrs = 0.05\n",
    "for iou_thrs in [\n",
    "    0.05,\n",
    "    # 0.1,\n",
    "    # 0.3\n",
    "]:\n",
    "\n",
    "    destination_folder = f\"generated_bb (thrs={iou_thrs})\"\n",
    "\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    os.makedirs(os.path.join(destination_folder, \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(destination_folder, \"val\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(destination_folder, \"test\"), exist_ok=True)\n",
    "\n",
    "    for idx in trange(len(detect_eval_dataset)):\n",
    "        fig = plot_result_for_models(\n",
    "            models,\n",
    "            train_infos,\n",
    "            detect_eval_dataset,\n",
    "            device,\n",
    "            idx=idx,\n",
    "            legend_elements=legend_elements,\n",
    "            disease_cmap=DISEASE_CMAP,\n",
    "            roi_head_thrs=iou_thrs,\n",
    "        )\n",
    "        instance = detect_eval_dataset.df.iloc[idx]\n",
    "        fig.savefig(\n",
    "            os.path.join(\n",
    "                destination_folder,\n",
    "                instance[\"split\"],\n",
    "                f\"{instance['dicom_id']} ({idx}).png\",\n",
    "            )\n",
    "        )\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close(\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_result_for_models(\n",
    "#     models,\n",
    "#     train_infos,\n",
    "#     detect_eval_dataset,\n",
    "#     device,\n",
    "#     idx=idx,\n",
    "#     legend_elements=legend_elements,\n",
    "#     disease_cmap=DISEASE_CMAP,\n",
    "#     roi_head_thrs=0.3,\n",
    "# )\n",
    "# instance = detect_eval_dataset.df.iloc[idx]\n",
    "# # fig.savefig(os.path.join(\"generated_bb\", instance['split'], f\"{instance['dicom_id']} ({idx}).png\"))\n",
    "# # plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
