{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils.print as print_f\n",
    "\n",
    "from utils.coco_eval import get_eval_params_dict\n",
    "from utils.engine import xami_train_one_epoch, xami_evaluate, get_iou_types\n",
    "from utils.plot import plot_losses, plot_train_val_ap_ars, get_ap_ar_for_train_val\n",
    "from utils.save import get_data_from_metric_logger\n",
    "from utils.coco_utils import get_cocos\n",
    "\n",
    "from models.setup import ModelSetup\n",
    "from models.build import create_model_from_setup\n",
    "from models.train import TrainingInfo\n",
    "from utils.save import check_best, end_train\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from utils.eval import get_ar_ap\n",
    "from utils.train import get_optimiser, get_lr_scheduler, print_params_setup\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS, XAMI_MIMIC_PATH\n",
    "from  datetime import datetime\n",
    "import torch.optim as optim\n",
    "from models.dynamic_loss import DynamicWeightedLoss\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n"
     ]
    }
   ],
   "source": [
    "device = clean_memory_get_device()\n",
    "reproducibility()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_iobb = True\n",
    "io_type_str = \"IoBB\" if use_iobb else \"IoU\"\n",
    "labels_cols = DEFAULT_REFLACX_LABEL_COLS\n",
    "iou_thrs = np.array([0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_setup =ModelSetup(\n",
    "        name=\"CXR\",\n",
    "        use_clinical=False,\n",
    "        use_custom_model=True,\n",
    "        use_early_stop_model=True,\n",
    "        best_ar_val_model_path=None,\n",
    "        best_ap_val_model_path=None,\n",
    "        final_model_path=None,\n",
    "        backbone=\"resnet50\",\n",
    "        optimiser=\"sgd\",\n",
    "        lr=1e-3,\n",
    "        # lr=1e-4,\n",
    "        # weight_decay=0.001,\n",
    "        weight_decay=0,\n",
    "        pretrained=True,\n",
    "        record_training_performance=True,\n",
    "        dataset_mode=\"unified\",\n",
    "        image_size=512,\n",
    "        backbone_out_channels=16,\n",
    "        batch_size=4,\n",
    "        warmup_epochs=0,\n",
    "        lr_scheduler=\"ReduceLROnPlateau\",\n",
    "        # lr_scheduler=None,\n",
    "        reduceLROnPlateau_factor=0.1,\n",
    "        reduceLROnPlateau_patience=500,\n",
    "        reduceLROnPlateau_full_stop=False,\n",
    "        multiStepLR_milestones=[30, 50, 70, 90],\n",
    "        multiStepLR_gamma=0.1,\n",
    "        representation_size=64, # 32\n",
    "        mask_hidden_layers=256,\n",
    "        using_fpn=True,\n",
    "        use_mask=False,\n",
    "        clinical_expand_dropout_rate=0,\n",
    "        clinical_conv_dropout_rate=0,\n",
    "        clinical_input_channels=32,\n",
    "        clinical_num_len=9,\n",
    "        clinical_conv_channels=32,\n",
    "        fuse_conv_channels=32,\n",
    "        fuse_dropout_rate=0,\n",
    "        box_head_dropout_rate=0,\n",
    "        fuse_depth=4,\n",
    "        fusion_strategy=\"add\",\n",
    "        fusion_residule=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Preparing for the training.====================\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Load custom model\n",
      "Using ResNet as backbone\n",
      "Using pretrained backbone. resnet50\n",
      "Not using pretrained MaksRCNN model.\n"
     ]
    }
   ],
   "source": [
    "print_f.print_title(\"Preparing for the training.\")\n",
    "\n",
    "train_info = TrainingInfo(model_setup)\n",
    "\n",
    "################ Datasets ################\n",
    "dataset_params_dict = {\n",
    "    \"XAMI_MIMIC_PATH\": XAMI_MIMIC_PATH,\n",
    "    \"with_clinical\": model_setup.use_clinical,\n",
    "    \"dataset_mode\": model_setup.dataset_mode,\n",
    "    \"bbox_to_mask\": model_setup.use_mask,\n",
    "    \"labels_cols\": labels_cols,\n",
    "}\n",
    "\n",
    "detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "    dataset_params_dict=dataset_params_dict,\n",
    ")\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, batch_size=model_setup.batch_size,\n",
    ")\n",
    "\n",
    "train_coco, val_coco, test_coco = get_cocos(\n",
    "    train_dataloader, val_dataloader, test_dataloader\n",
    ")\n",
    "\n",
    "eval_params_dict = get_eval_params_dict(\n",
    "    detect_eval_dataset, iou_thrs=iou_thrs, use_iobb=use_iobb,\n",
    ")\n",
    "\n",
    "model = create_model_from_setup(\n",
    "    labels_cols,\n",
    "    model_setup,\n",
    "    rpn_nms_thresh=0.3,\n",
    "    box_detections_per_img=10,\n",
    "    box_nms_thresh=0.2,\n",
    "    rpn_score_thresh=0.0,\n",
    "    box_score_thresh=0.05,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model]: 28,202,221\n",
      "[model.backbone]: 26,799,296\n",
      "[model.rpn]: 593,935\n",
      "[model.roi_heads]: 808,990\n",
      "[model.roi_heads.box_head]: 807,040\n",
      "[model.roi_heads.box_head.fc6]: 802,880\n",
      "[model.roi_heads.box_head.fc7]: 4,160\n",
      "[model.roi_heads.box_predictor]: 1,950\n",
      "Using SGD as optimizer with lr=0.001\n",
      "====================Start training. Preparing Tooke [163] sec====================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dynamic_loss_weight = None\n",
    "dynamic_loss_weight = DynamicWeightedLoss()\n",
    "dynamic_loss_weight.to(device)\n",
    "print_params_setup(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "if dynamic_loss_weight:\n",
    "    params += [p for p in dynamic_loss_weight.parameters() if p.requires_grad]\n",
    "\n",
    "iou_types = get_iou_types(model, model_setup)\n",
    "optimizer = get_optimiser(params, model_setup)\n",
    "lr_scheduler = get_lr_scheduler(optimizer, model_setup)\n",
    "\n",
    "current_time = datetime.now()\n",
    "\n",
    "print_f.print_title(\n",
    "    f\"Start training. Preparing Tooke [{ (current_time - train_info.start_t).seconds}] sec\"\n",
    ")\n",
    "\n",
    "train_info.start_t = datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.train.TrainingInfo at 0x2d12c59eb50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.save import save_checkpoint\n",
    "\n",
    "save_checkpoint(\n",
    "    train_info = train_info,\n",
    "    model=model,\n",
    "    val_ar=0,\n",
    "    val_ap=0,\n",
    "    test_ar=0,\n",
    "    test_ap=0,\n",
    "    optimizer=optimizer,\n",
    "    dynamic_weight= dynamic_loss_weight,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_ar_0_0000_ap_0_0000_test_ar_0_0000_ap_0_0000_epoch0_WithoutClincal_05-18-2022 00-03-22_CXR'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.final_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TrainedModels(Enum):\n",
    "    load = train_info.final_model_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load custom model\n",
      "Using ResNet as backbone\n",
      "Using pretrained backbone. resnet50\n",
      "Not using pretrained MaksRCNN model.\n",
      "Using SGD as optimizer with lr=0.001\n"
     ]
    }
   ],
   "source": [
    "from models.load import get_trained_model\n",
    "\n",
    "model, train_info, optimizer, dynamic_loss_weight = get_trained_model(\n",
    "        TrainedModels.load,\n",
    "        labels_cols,\n",
    "        device,\n",
    "        rpn_nms_thresh=0.3,\n",
    "        box_detections_per_img=10,\n",
    "        box_nms_thresh=0.2,\n",
    "        rpn_score_thresh=0.0,\n",
    "        box_score_thresh=0.05,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
