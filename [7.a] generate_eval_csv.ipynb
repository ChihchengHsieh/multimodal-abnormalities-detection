{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\models\\detectors\\rcnn.py:102: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n"
     ]
    }
   ],
   "source": [
    "import os, gc, torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from models.load import TrainedModels\n",
    "\n",
    "from utils.eval import save_iou_results\n",
    "from utils.engine import xami_evaluate, get_iou_types\n",
    "from models.load import get_trained_model\n",
    "from utils.coco_eval import get_eval_params_dict\n",
    "from data.datasets import  OurRadiologsitsDataset, collate_fn\n",
    "from our_radiologist.load import get_anns\n",
    "from utils.coco_utils import get_cocos, get_coco_api_from_dataset\n",
    "from utils.eval import get_ap_ar\n",
    "from utils.print import print_title\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "from data.constants import XAMI_MIMIC_PATH, DEFAULT_REFLACX_LABEL_COLS\n",
    "from utils.constants import full_iou_thrs, iou_thrs_5to95\n",
    "from data.load  import seed_worker, get_dataloader_g\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Suppress the assignement warning from pandas.\n",
    "pd.options.mode.chained_assignment = None  # default='warn\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n"
     ]
    }
   ],
   "source": [
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TrainedModels(Enum):\n",
    "    CXR_Clinial_fusion1_fusion2=\"val_ar_0_5436_ap_0_1911_test_ar_0_5476_ap_0_3168_epoch49_WithClincal_05-23-2022 12-06-22_CXR_Clinical_roi_heads_spatialisation\"\n",
    "    CXR_Clinical_fusion1 = \"val_ar_0_5476_ap_0_1984_test_ar_0_6038_ap_0_2757_epoch41_WithClincal_05-30-2022 08-01-54_CXR_Clinical_fusion1\"\n",
    "    CXR_Clinical_fusion2= \"val_ar_0_4369_ap_0_2098_test_ar_0_4940_ap_0_2218_epoch58_WithClincal_05-30-2022 13-58-43_CXR_Clinical_fusion2\"\n",
    "    CXR=\"val_ar_0_5659_ap_0_1741_test_ar_0_5390_ap_0_1961_epoch36_WithoutClincal_05-29-2022 12-29-51_CXR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_iou_thrs = iou_thrs_5to95\n",
    "all_range_iou_thrs = full_iou_thrs\n",
    "score_thresholds = [0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_spa_layers = itertools.chain.from_iterable([[\n",
    "        nn.Linear(\n",
    "        64,\n",
    "        64,\n",
    "        ),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.LeakyReLU(),\n",
    "    ]\n",
    "    for _ in range(5)])\n",
    "\n",
    "pre_spa = nn.Sequential(\n",
    "    *pre_spa_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       "  (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): LeakyReLU(negative_slope=0.01)\n",
       "  (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): LeakyReLU(negative_slope=0.01)\n",
       "  (9): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): LeakyReLU(negative_slope=0.01)\n",
       "  (12): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): LeakyReLU(negative_slope=0.01)\n",
       "  (15): Linear(in_features=64, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_spa.append(nn.Linear(64, 64),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       "  (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): LeakyReLU(negative_slope=0.01)\n",
       "  (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): LeakyReLU(negative_slope=0.01)\n",
       "  (9): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): LeakyReLU(negative_slope=0.01)\n",
       "  (12): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): LeakyReLU(negative_slope=0.01)\n",
       "  (15): Linear(in_features=64, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_spa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load custom model\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "Mask Hidden Layers 256\n",
      "Using SGD as optimizer with lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [01:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9880/2658385801.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m         )\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         train_coco, val_coco, test_coco = get_cocos(\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\utils\\coco_utils.py\u001b[0m in \u001b[0;36mget_cocos\u001b[1;34m(train_dataloader, val_dataloader, test_dataloader)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_cocos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtrain_coco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mval_coco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtest_coco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\utils\\coco_utils.py\u001b[0m in \u001b[0;36mget_coco_api_from_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCocoDetection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_to_coco_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\utils\\coco_utils.py\u001b[0m in \u001b[0;36mconvert_to_coco_api\u001b[1;34m(ds)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;31m# targets = ds.get_annotations(img_idx)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;31m# img, clinical_num, clinical_cat, targets = ds[img_idx]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\data\\datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    278\u001b[0m                 )\n\u001b[0;32m    279\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m                 clinical_num = torch.tensor(\n\u001b[0m\u001b[0;32m    281\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclinical_numerical_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                 ).float()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for select_model in tqdm([\n",
    "    TrainedModels.CXR_Clinical_fusion1,\n",
    "    TrainedModels.CXR_Clinical_fusion2,\n",
    "    TrainedModels.CXR_Clinial_fusion1_fusion2,\n",
    "    TrainedModels.CXR\n",
    "]):\n",
    "\n",
    "    for score_thrs in score_thresholds:\n",
    "\n",
    "        model, train_info, _, _ = get_trained_model(\n",
    "            select_model,\n",
    "            DEFAULT_REFLACX_LABEL_COLS,\n",
    "            device,\n",
    "            rpn_nms_thresh=0.3,\n",
    "            box_detections_per_img=10,\n",
    "            box_nms_thresh=0.2,\n",
    "            rpn_score_thresh=0.0,\n",
    "            box_score_thresh=score_thrs,\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        iou_types = get_iou_types(model, train_info.model_setup)\n",
    "\n",
    "        model_setup = train_info.model_setup\n",
    "        dataset_params_dict = {\n",
    "            \"XAMI_MIMIC_PATH\": XAMI_MIMIC_PATH,\n",
    "            \"with_clinical\": model_setup.use_clinical,\n",
    "            \"dataset_mode\": model_setup.dataset_mode,\n",
    "            \"bbox_to_mask\": model_setup.use_mask,\n",
    "            \"normalise_clinical_num\": model_setup.normalise_clinical_num,\n",
    "            \"labels_cols\": DEFAULT_REFLACX_LABEL_COLS,\n",
    "        }\n",
    "\n",
    "        detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "            dataset_params_dict=dataset_params_dict,\n",
    "        )\n",
    "\n",
    "        train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "            train_dataset, val_dataset, test_dataset, batch_size=4,\n",
    "        )\n",
    "\n",
    "        train_coco, val_coco, test_coco = get_cocos(\n",
    "            train_dataloader, val_dataloader, test_dataloader\n",
    "        )\n",
    "\n",
    "        radiologists_ann = get_anns(\"radiologists_annotated\", detect_eval_dataset)\n",
    "\n",
    "        radiologist_dataset = OurRadiologsitsDataset(\n",
    "            detect_eval_dataset, radiologists_ann\n",
    "        )\n",
    "        radiologist_dataloader = torch.utils.data.DataLoader(\n",
    "            radiologist_dataset,\n",
    "            batch_size=4,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=get_dataloader_g(0),\n",
    "        )\n",
    "\n",
    "        radiologists_coco = get_coco_api_from_dataset(radiologist_dataloader.dataset)\n",
    "\n",
    "        normal_eval_params_dict = get_eval_params_dict(\n",
    "            detect_eval_dataset, iou_thrs=normal_iou_thrs,\n",
    "        )\n",
    "\n",
    "        all_range_eval_params_dict = get_eval_params_dict(\n",
    "            detect_eval_dataset, iou_thrs=all_range_iou_thrs,\n",
    "        )\n",
    "\n",
    "        all_cat_ids = [None] + [\n",
    "            detect_eval_dataset.disease_to_idx(d)\n",
    "            for d in detect_eval_dataset.labels_cols\n",
    "        ]\n",
    "\n",
    "        for cat_id in all_cat_ids:\n",
    "            cat_ids = (\n",
    "                [\n",
    "                    detect_eval_dataset.disease_to_idx(d)\n",
    "                    for d in detect_eval_dataset.labels_cols\n",
    "                ]\n",
    "                if cat_id is None\n",
    "                else [cat_id]\n",
    "            )\n",
    "\n",
    "            if not (cat_ids is None):\n",
    "                all_range_eval_params_dict[\"bbox\"].catIds = cat_ids\n",
    "                all_range_eval_params_dict[\"segm\"].catIds = cat_ids\n",
    "\n",
    "            train_evaluator, _ = xami_evaluate(\n",
    "                model,\n",
    "                train_dataloader,\n",
    "                device=device,\n",
    "                params_dict=all_range_eval_params_dict,\n",
    "                coco=train_coco,\n",
    "                iou_types=iou_types,\n",
    "                # score_thres=score_thres,\n",
    "            )\n",
    "\n",
    "            test_evaluator, _ = xami_evaluate(\n",
    "                model,\n",
    "                test_dataloader,\n",
    "                device=device,\n",
    "                params_dict=all_range_eval_params_dict,\n",
    "                coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                # score_thres=score_thres,\n",
    "            )\n",
    "\n",
    "            val_evaluator, _ = xami_evaluate(\n",
    "                model,\n",
    "                val_dataloader,\n",
    "                device=device,\n",
    "                params_dict=all_range_eval_params_dict,\n",
    "                coco=val_coco,\n",
    "                iou_types=iou_types,\n",
    "                # score_thres=score_thres,\n",
    "            )\n",
    "\n",
    "            radiologist_evaluator, _ = xami_evaluate(\n",
    "                model,\n",
    "                radiologist_dataloader,\n",
    "                device=device,\n",
    "                params_dict=all_range_eval_params_dict,\n",
    "                coco=radiologists_coco,\n",
    "                iou_types=iou_types,\n",
    "            )\n",
    "\n",
    "            if cat_id is None:\n",
    "                disease_str = \"all\"\n",
    "            else:\n",
    "                disease_str = detect_eval_dataset.label_idx_to_disease(cat_id)\n",
    "\n",
    "            save_iou_results(\n",
    "                train_evaluator,\n",
    "                f\"train_{disease_str}_score_thrs{score_thrs}\",\n",
    "                select_model.value,\n",
    "            )\n",
    "            save_iou_results(\n",
    "                test_evaluator,\n",
    "                f\"test_{disease_str}_score_thrs{score_thrs}\",\n",
    "                select_model.value,\n",
    "            )\n",
    "            save_iou_results(\n",
    "                val_evaluator,\n",
    "                f\"val_{disease_str}_score_thrs{score_thrs}\",\n",
    "                select_model.value,\n",
    "            )\n",
    "            save_iou_results(\n",
    "                radiologist_evaluator,\n",
    "                f\"our_{disease_str}_score_thrs{score_thrs}\",\n",
    "                select_model.value,\n",
    "            )\n",
    "\n",
    "            train_ap_ar = get_ap_ar(\n",
    "                train_evaluator, areaRng=\"all\", maxDets=10, iouThr=0.5,\n",
    "            )\n",
    "\n",
    "            test_ap_ar = get_ap_ar(\n",
    "                test_evaluator, areaRng=\"all\", maxDets=10, iouThr=0.5,\n",
    "            )\n",
    "            val_ap_ar = get_ap_ar(\n",
    "                val_evaluator, areaRng=\"all\", maxDets=10, iouThr=0.5,\n",
    "            )\n",
    "            our_ap_ar = get_ap_ar(\n",
    "                radiologist_evaluator, areaRng=\"all\", maxDets=10, iouThr=0.5,\n",
    "            )\n",
    "\n",
    "            df = pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"dataset\": \"train\",\n",
    "                        f\"AP@[IoBB = 0.50]\": train_ap_ar[\"ap\"],\n",
    "                        f\"AR@[IoBB = 0.50]\": train_ap_ar[\"ar\"],\n",
    "                    },\n",
    "                    {\n",
    "                        \"dataset\": \"test\",\n",
    "                        f\"AP@[IoBB = 0.50]\": test_ap_ar[\"ap\"],\n",
    "                        f\"AR@[IoBB = 0.50]\": test_ap_ar[\"ar\"],\n",
    "                    },\n",
    "                    {\n",
    "                        \"dataset\": \"val\",\n",
    "                        f\"AP@[IoBB = 0.50]\": val_ap_ar[\"ap\"],\n",
    "                        f\"AR@[IoBB = 0.50]\": val_ap_ar[\"ar\"],\n",
    "                    },\n",
    "                    {\n",
    "                        \"dataset\": \"our\",\n",
    "                        f\"AP@[IoBB = 0.50]\": our_ap_ar[\"ap\"],\n",
    "                        f\"AR@[IoBB = 0.50]\": our_ap_ar[\"ar\"],\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            df.to_csv(\n",
    "                os.path.join(\n",
    "                    \"eval_results\",\n",
    "                    f\"{select_model.value}_{disease_str}_score_thrs{score_thrs}.csv\",\n",
    "                )\n",
    "            )\n",
    "            print_title(disease_str)\n",
    "            print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
