{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out our model here.\n",
    "\n",
    "We test our mutli-modal Faster R-CNN with MIMIC dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike8\\Desktop\\multimodal-abnormalities-detection\\models\\detectors\\rcnn.py:832: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils.print as print_f\n",
    "\n",
    "from utils.coco_eval import get_eval_params_dict\n",
    "from utils.engine import xami_train_one_epoch, xami_evaluate\n",
    "from utils.plot import plot_loss, plot_train_val_evaluators, plot_evaluator\n",
    "\n",
    "from models.setup import ModelSetup\n",
    "from models.build import create_model_from_setup\n",
    "from models.train import TrainingInfo\n",
    "from utils.save import check_best, end_train\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from utils.eval import get_ar_ap\n",
    "from utils.train import get_optimiser\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from utils.constants import full_iou_thrs\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS, XAMI_MIMIC_PATH\n",
    "from  datetime import datetime\n",
    "\n",
    "\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n"
     ]
    }
   ],
   "source": [
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your MIMIC folde path here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_iobb = True\n",
    "io_type_str = \"IoBB\" if use_iobb else \"IoU\"\n",
    "\n",
    "model_setup = ModelSetup(\n",
    "    name=\"forward_testing\",\n",
    "    use_clinical=True,\n",
    "    use_custom_model=True,\n",
    "    use_early_stop_model=True,\n",
    "    backbone=\"mobilenet_v3\",  # [mobilenet_v3]\n",
    "    optimiser=\"sgd\",\n",
    "    lr=1e-2,\n",
    "    pretrained=True,\n",
    "    dataset_mode=\"unified\",\n",
    "    image_size=256,\n",
    "    weight_decay=1e-3,\n",
    "    record_training_performance=True,\n",
    "    using_fpn=False,\n",
    "    backbone_out_channels=16,  # shrink size test [16, 32]\n",
    "    representation_size=32,  # shrink size test [32, 64, 128]\n",
    "    # mask_hidden_layers=64,\n",
    "    use_mask=False,\n",
    "    batch_size=4,\n",
    "    box_head_dropout_rate=0,  # [0, 0.1, 0.2, 0.3]\n",
    "    warmup_epochs=0,\n",
    "    lr_scheduler=\"ReduceLROnPlateau\",  # [ReduceLROnPlateau, MultiStepLR]\n",
    "    reduceLROnPlateau_factor=0.1,\n",
    "    reduceLROnPlateau_patience=3,\n",
    "    multiStepLR_milestones=[30, 50, 70, 90],\n",
    "    multiStepLR_gamma=0.1,\n",
    "\n",
    "    clinical_conv_channels=32,\n",
    "    fuse_conv_channels=32,\n",
    "    fuse_depth=4,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate datasets and dataloaders\n",
    "The batch size is also defined in this section. For testing purpose, we only set it as 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cols = [\n",
    "    \"Enlarged cardiac silhouette\",\n",
    "    \"Atelectasis\",\n",
    "    \"Pleural abnormality\",\n",
    "    \"Consolidation\",\n",
    "    \"Pulmonary edema\",\n",
    "    #  'Groundglass opacity', # 6th disease.\n",
    "]\n",
    "\n",
    "dataset_params_dict = {\n",
    "    \"XAMI_MIMIC_PATH\": XAMI_MIMIC_PATH,\n",
    "    \"with_clinical\": model_setup.use_clinical,\n",
    "    \"dataset_mode\": model_setup.dataset_mode,\n",
    "    \"bbox_to_mask\": True,\n",
    "    \"labels_cols\": labels_cols,\n",
    "}\n",
    "\n",
    "detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "    dataset_params_dict=dataset_params_dict\n",
    ")\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We used to have 590, after unifying, we will have 590.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We used to have {len(detect_eval_dataset.df.dicom_id)}, after unifying, we will have {len(detect_eval_dataset.df.dicom_id.unique())}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example instance from dataset\n",
    "We show what's inside a single instance. It will provide:\n",
    "\n",
    "- Images\n",
    "- Clinical data\n",
    "- Targets (Dictionary)\n",
    "\n",
    "And, inside the target, there're:\n",
    "\n",
    "- boxes (bounding boxes of abnormality)\n",
    "- lable (disease index (Note: the class **0** means the background))\n",
    "- image_id (idx to get that image)\n",
    "- area (the areas that bouding boxes contain)\n",
    "- iscrowd (if it's a place with multiple bouding boxes, we assume all the the bouding boxes are not crowd.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5608, 0.5608, 0.5569,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5569, 0.5647, 0.5647,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5490, 0.5569, 0.5608,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.7686, 0.7686, 0.7647,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7608, 0.7647, 0.7608,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7529, 0.7569, 0.7569,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[0.5608, 0.5608, 0.5569,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5569, 0.5647, 0.5647,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5490, 0.5569, 0.5608,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.7686, 0.7686, 0.7647,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7608, 0.7647, 0.7608,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7529, 0.7569, 0.7569,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[0.5608, 0.5608, 0.5569,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5569, 0.5647, 0.5647,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5490, 0.5569, 0.5608,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.7686, 0.7686, 0.7647,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7608, 0.7647, 0.7608,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.7529, 0.7569, 0.7569,  ..., 1.0000, 1.0000, 1.0000]]]),\n",
       " tensor([ 69.0000,  98.1000,  90.0000,  18.0000,  99.0000, 184.0000,  75.0000,\n",
       "          13.0000,   3.0000]),\n",
       " tensor([0], dtype=torch.int32),\n",
       " {'boxes': tensor([[ 734., 1204., 2211., 2175.],\n",
       "          [ 831., 1204., 2223., 2310.],\n",
       "          [ 692., 1364., 2257., 2261.],\n",
       "          [ 887., 1081., 2248., 2344.]], dtype=torch.float64),\n",
       "  'labels': tensor([1, 1, 1, 1]),\n",
       "  'image_id': tensor([0]),\n",
       "  'area': tensor([1434167., 1539552., 1403805., 1718943.], dtype=torch.float64),\n",
       "  'iscrowd': tensor([0, 0, 0, 0]),\n",
       "  'dicom_id': '34cedb74-d0996b40-6d218312-a9174bea-d48dc033',\n",
       "  'image_path': 'D:\\\\XAMI-MIMIC\\\\patient_18111516\\\\CXR-JPG\\\\s55032240\\\\34cedb74-d0996b40-6d218312-a9174bea-d48dc033.jpg',\n",
       "  'masks': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "          [[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "          [[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "          [[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model.\n",
    "\n",
    "We define he models here. Two backbone examples are in the below code section. The MobileNet is a light weight network, and ResNet is heavier, but usually perform better. In our case, the calculation is not the most important factor; therefore, we chose ResNet with feature pyramid networks (FPN) backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load custom model\n",
      "Using pretrained backbone. mobilenet_v3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultimodalMaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ConvNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(576, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (rpn): XAMIRegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(16, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(16, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): XAMIRoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): XAMITwoMLPHead(\n",
       "      (fc6): Sequential(\n",
       "        (0): Linear(in_features=784, out_features=32, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=True)\n",
       "      )\n",
       "      (fc7): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=32, out_features=6, bias=True)\n",
       "      (bbox_pred): Linear(in_features=32, out_features=24, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gender_emb_layer): Embedding(2, 23)\n",
       "  (clinical_expand_conv): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout2d(p=0, inplace=True)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout2d(p=0, inplace=True)\n",
       "    (8): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Dropout2d(p=0, inplace=True)\n",
       "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Dropout2d(p=0, inplace=True)\n",
       "    (16): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Dropout2d(p=0, inplace=True)\n",
       "    (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Dropout2d(p=0, inplace=True)\n",
       "    (24): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Dropout2d(p=0, inplace=True)\n",
       "    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU(inplace=True)\n",
       "    (31): Dropout2d(p=0, inplace=True)\n",
       "    (32): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (34): ReLU(inplace=True)\n",
       "    (35): Dropout2d(p=0, inplace=True)\n",
       "    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): Dropout2d(p=0, inplace=True)\n",
       "    (40): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Dropout2d(p=0, inplace=True)\n",
       "    (44): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (45): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (46): ReLU(inplace=True)\n",
       "    (47): Dropout2d(p=0, inplace=True)\n",
       "    (48): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (50): ReLU(inplace=True)\n",
       "    (51): Dropout2d(p=0, inplace=True)\n",
       "    (52): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (53): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (54): ReLU(inplace=True)\n",
       "    (55): Dropout2d(p=0, inplace=True)\n",
       "    (56): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (57): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (58): ReLU(inplace=True)\n",
       "    (59): Dropout2d(p=0, inplace=True)\n",
       "    (60): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (61): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (62): ReLU(inplace=True)\n",
       "    (63): Dropout2d(p=0, inplace=True)\n",
       "  )\n",
       "  (clinical_convs): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout2d(p=0, inplace=True)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout2d(p=0, inplace=True)\n",
       "    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Dropout2d(p=0, inplace=True)\n",
       "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Dropout2d(p=0, inplace=True)\n",
       "    (16): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Dropout2d(p=0, inplace=True)\n",
       "  )\n",
       "  (fuse_convs): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout2d(p=0, inplace=True)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout2d(p=0, inplace=True)\n",
       "    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Dropout2d(p=0, inplace=True)\n",
       "    (12): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Dropout2d(p=0, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model_from_setup(\n",
    "    labels_cols,\n",
    "    model_setup,\n",
    "    rpn_nms_thresh=0.3,\n",
    "    box_detections_per_img=10,\n",
    "    box_nms_thresh=0.2,\n",
    "    rpn_score_thresh=0.0,\n",
    "    box_score_thresh=0.05,\n",
    "    # image_size=model_setup.image_size,\n",
    "    # clinical_conv_channels=64,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model]: 1,223,303\n",
      "[model.backbone]: 1,009,968\n",
      "[model.rpn]: 3,595\n",
      "[model.roi_heads]: 27,166\n",
      "[model.roi_heads.box_head]: 26,176\n",
      "[model.roi_heads.box_head.fc6]: 25,120\n",
      "[model.roi_heads.box_head.fc7]: 1,056\n",
      "[model.roi_heads.box_predictor]: 990\n",
      "[model.clinical_convs]: 41,904\n",
      "[model.fuse_convs]: 32,592\n"
     ]
    }
   ],
   "source": [
    "from utils.train import print_params_setup\n",
    "print_params_setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data to feed\n",
    "\n",
    "We prepare three main data to test the model:\n",
    "\n",
    "- CXR image\n",
    "- Clinical data\n",
    "- Target\n",
    "\n",
    "And, for each data, we adjust the format to what the model expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "data = train_dataset.prepare_input_from_data(data, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Feedforawrd (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [gt_label[idxs] for gt_label, idxs in zip(gt_labels, mask_matched_idxs)]\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-1][0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2544, 3056])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-1][0]['masks'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, targets = data\n",
    "# images, targets = model.transform(images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "loss_dict, outputs = model(*data[:-1], targets=data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results we get.\n",
    "Four different losses are given in the result, we will use these losses to optimise the network while training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Feedforawrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection.\n",
    "\n",
    "A detection contain *boxes*, *lables*, and *scores*.\n",
    "\n",
    "- *boxes*: All the bounding boxes for this image. \n",
    "- *lables*: Labels corresponded to the bounding boxes.\n",
    "- *score*: Score (Confidence) for each boudning box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'loss_classifier': tensor(1.8429, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       "  'loss_box_reg': tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  'loss_objectness': tensor(0.6932, device='cuda:0',\n",
       "         grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       "  'loss_rpn_box_reg': tensor(0.4561, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)},\n",
       " [{'boxes': tensor([[ 921.3475,  916.9742, 1433.6675, 1630.9636],\n",
       "           [   0.0000,    0.0000, 1082.6816,  457.8885],\n",
       "           [   0.0000,    0.0000,  190.6875,  162.5804],\n",
       "           [   0.0000,    0.0000, 3039.1206, 2544.0000],\n",
       "           [ 485.3980,  921.4603,  865.1107, 1537.3938],\n",
       "           [2363.5857, 1125.2233, 2666.8264, 1512.2043],\n",
       "           [2361.2820, 1139.0974, 2669.3003, 1502.2478],\n",
       "           [ 921.4305,  945.2888, 1434.4622, 1609.0178],\n",
       "           [   0.0000,   10.6675, 1082.4666,  443.1554],\n",
       "           [   0.0000,    3.7876,  190.6496,  157.3491]], device='cuda:0',\n",
       "          grad_fn=<StackBackward0>),\n",
       "   'labels': tensor([4, 4, 4, 4, 4, 4, 5, 5, 5, 5], device='cuda:0'),\n",
       "   'scores': tensor([0.1917, 0.1915, 0.1915, 0.1915, 0.1912, 0.1898, 0.1813, 0.1809, 0.1803,\n",
       "           0.1803], device='cuda:0', grad_fn=<IndexBackward0>)},\n",
       "  {'boxes': tensor([[0.0000e+00, 0.0000e+00, 1.5767e+02, 1.9494e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 6.2990e+02, 7.7898e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 2.5136e+03, 3.0560e+03],\n",
       "           [0.0000e+00, 5.4081e+00, 1.5856e+02, 1.8863e+02],\n",
       "           [0.0000e+00, 2.1611e+01, 6.3348e+02, 7.5378e+02],\n",
       "           [0.0000e+00, 8.6464e+01, 2.5278e+03, 3.0158e+03],\n",
       "           [2.7524e-01, 0.0000e+00, 1.5503e+02, 1.9219e+02],\n",
       "           [1.0997e+00, 0.0000e+00, 6.1939e+02, 7.6800e+02],\n",
       "           [4.3881e+00, 0.0000e+00, 2.4716e+03, 3.0560e+03],\n",
       "           [0.0000e+00, 0.0000e+00, 1.6125e+02, 1.9052e+02]], device='cuda:0',\n",
       "          grad_fn=<StackBackward0>),\n",
       "   'labels': tensor([4, 4, 4, 5, 5, 5, 1, 1, 1, 2], device='cuda:0'),\n",
       "   'scores': tensor([0.1856, 0.1856, 0.1856, 0.1853, 0.1853, 0.1853, 0.1636, 0.1636, 0.1636,\n",
       "           0.1564], device='cuda:0', grad_fn=<IndexBackward0>)},\n",
       "  {'boxes': tensor([[   0.0000,    0.0000,  445.6779, 1099.9257],\n",
       "           [   0.0000,    0.0000,  158.9057,  193.6868],\n",
       "           [   0.0000,    0.0000, 2534.9031, 3056.0000],\n",
       "           [  42.1036, 1603.8828,  304.7372, 2589.3237],\n",
       "           [  40.4321, 1646.7803,  306.1373, 2566.1541],\n",
       "           [   0.0000,   31.8909,  446.4077, 1077.6226],\n",
       "           [   0.0000,    5.6157,  159.1659,  189.7594],\n",
       "           [   0.0000,   89.8518, 2539.0535, 3036.1765],\n",
       "           [   0.0000,    0.0000,  453.7978, 1082.1863],\n",
       "           [   0.0000,    0.0000,  161.8008,  190.5631]], device='cuda:0',\n",
       "          grad_fn=<StackBackward0>),\n",
       "   'labels': tensor([4, 4, 4, 4, 5, 5, 5, 5, 2, 2], device='cuda:0'),\n",
       "   'scores': tensor([0.1897, 0.1897, 0.1897, 0.1893, 0.1835, 0.1800, 0.1800, 0.1800, 0.1642,\n",
       "           0.1642], device='cuda:0', grad_fn=<IndexBackward0>)},\n",
       "  {'boxes': tensor([[   0.0000,    8.9700,  765.5101,  625.6027],\n",
       "           [   0.0000,    3.2181,  131.6163,  224.4394],\n",
       "           [   0.0000,   35.8078, 3056.0000, 2497.3789],\n",
       "           [1570.3975, 1485.0966, 1856.2424, 2012.9174],\n",
       "           [ 743.0907, 1411.3096, 1156.0762, 1865.4376],\n",
       "           [   0.0000,    0.0000,  754.5323,  658.4173],\n",
       "           [   0.0000,    0.0000,  129.7288,  236.2119],\n",
       "           [   0.0000,    0.0000, 3018.0579, 2544.0000],\n",
       "           [ 743.7611, 1397.8715, 1152.7725, 1884.5975],\n",
       "           [1574.4443, 1477.7200, 1863.7859, 2000.7319]], device='cuda:0',\n",
       "          grad_fn=<StackBackward0>),\n",
       "   'labels': tensor([5, 5, 5, 4, 5, 4, 4, 4, 4, 2], device='cuda:0'),\n",
       "   'scores': tensor([0.1895, 0.1895, 0.1895, 0.1860, 0.1849, 0.1845, 0.1845, 0.1845, 0.1834,\n",
       "           0.1739], device='cuda:0', grad_fn=<IndexBackward0>)}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict, outputs "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a402e4e4296f2d4bed1c089fb7c7e828933dcbfe50698b381e393c052eea855"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
