{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, warnings\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from models.build import NoAction\n",
    "from utils.train import num_params\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_creating_fns = [\n",
    "    models.resnet18,\n",
    "    models.resnet50,\n",
    "    models.alexnet,\n",
    "    models.vgg16,\n",
    "    models.squeezenet1_0,\n",
    "    models.densenet161,\n",
    "    # models.inception_v3,\n",
    "    # models.googlenet,\n",
    "    models.shufflenet_v2_x1_0,\n",
    "    models.mobilenet_v2,\n",
    "    models.mobilenet_v3_large,\n",
    "    models.mobilenet_v3_small,\n",
    "    models.resnext50_32x4d,\n",
    "    models.wide_resnet50_2,\n",
    "    models.mnasnet1_0,\n",
    "    models.efficientnet_b0,\n",
    "    models.efficientnet_b1,\n",
    "    models.efficientnet_b2,\n",
    "    models.efficientnet_b3,\n",
    "    models.efficientnet_b4,\n",
    "    models.efficientnet_b5,\n",
    "    models.efficientnet_b6,\n",
    "    models.efficientnet_b7,\n",
    "    models.regnet_y_400mf,\n",
    "    models.regnet_y_800mf,\n",
    "    models.regnet_y_1_6gf,\n",
    "    models.regnet_y_3_2gf,\n",
    "    models.regnet_y_8gf,\n",
    "    models.regnet_y_16gf,\n",
    "    models.regnet_y_32gf,\n",
    "    models.regnet_y_128gf,\n",
    "    models.regnet_x_400mf,\n",
    "    models.regnet_x_800mf,\n",
    "    models.regnet_x_1_6gf,\n",
    "    models.regnet_x_3_2gf,\n",
    "    models.regnet_x_8gf,\n",
    "    models.regnet_x_16gf,\n",
    "    models.regnet_x_32gf,\n",
    "    models.vit_b_16,\n",
    "    models.vit_b_32,\n",
    "    models.vit_l_16,\n",
    "    models.vit_l_32,\n",
    "    models.convnext_tiny,\n",
    "    models.convnext_small,\n",
    "    models.convnext_base,\n",
    "    models.convnext_large,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.randn(1,3,1024,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| [resnet18] | Size: [11,176,512] | Out: [torch.Size([1, 512, 1, 1])] |\n",
      "| [resnet50] | Size: [23,508,032] | Out: [torch.Size([1, 2048, 1, 1])] |\n",
      "| [alexnet] | Size: [61,100,840] | Out: [torch.Size([1, 256, 31, 31])] |\n",
      "| [vgg16] | Size: [138,357,544] | Out: [torch.Size([1, 512, 32, 32])] |\n",
      "| [squeezenet1_0] | Size: [1,248,424] | Out: [torch.Size([1, 512, 63, 63])] |\n",
      "| [densenet161] | Size: [28,681,000] | Out: [torch.Size([1, 2208, 32, 32])] |\n",
      "| [shufflenet_v2_x1_0] | Size: [1,253,604] | Out: [torch.Size([1, 1024])] |\n",
      "| [mobilenet_v2] | Size: [3,504,872] | Out: [torch.Size([1, 1280, 32, 32])] |\n",
      "| [mobilenet_v3_large] | Size: [5,483,032] | Out: [torch.Size([1, 960, 32, 32])] |\n",
      "| [mobilenet_v3_small] | Size: [2,542,856] | Out: [torch.Size([1, 576, 32, 32])] |\n",
      "| [resnext50_32x4d] | Size: [22,979,904] | Out: [torch.Size([1, 2048, 1, 1])] |\n",
      "| [wide_resnet50_2] | Size: [66,834,240] | Out: [torch.Size([1, 2048, 1, 1])] |\n",
      "| [mnasnet1_0] | Size: [3,102,312] | Out: [torch.Size([1, 1280])] |\n",
      "| [efficientnet_b0] | Size: [5,288,548] | Out: [torch.Size([1, 1280, 32, 32])] |\n",
      "| [efficientnet_b1] | Size: [7,794,184] | Out: [torch.Size([1, 1280, 32, 32])] |\n",
      "| [efficientnet_b2] | Size: [9,109,994] | Out: [torch.Size([1, 1408, 32, 32])] |\n",
      "| [efficientnet_b3] | Size: [12,233,232] | Out: [torch.Size([1, 1536, 32, 32])] |\n",
      "| [efficientnet_b4] | Size: [19,341,616] | Out: [torch.Size([1, 1792, 32, 32])] |\n",
      "| [efficientnet_b5] | Size: [30,389,784] | Out: [torch.Size([1, 2048, 32, 32])] |\n",
      "| [efficientnet_b6] | Size: [43,040,704] | Out: [torch.Size([1, 2304, 32, 32])] |\n",
      "| [efficientnet_b7] | Size: [66,347,960] | Out: [torch.Size([1, 2560, 32, 32])] |\n",
      "| [regnet_y_400mf] | Size: [3,903,144] | Out: [torch.Size([1, 440])] |\n",
      "| [regnet_y_800mf] | Size: [5,647,512] | Out: [torch.Size([1, 784])] |\n",
      "| [regnet_y_1_6gf] | Size: [10,313,430] | Out: [torch.Size([1, 888])] |\n",
      "| [regnet_y_3_2gf] | Size: [17,923,338] | Out: [torch.Size([1, 1512])] |\n"
     ]
    }
   ],
   "source": [
    "for creator in model_creating_fns:\n",
    "    model = creator()   \n",
    "\n",
    "    out_channels = \"Unknown\"\n",
    "    \n",
    "    if hasattr(model, \"features\"):\n",
    "        out_channels = model.features(test_input).shape\n",
    "\n",
    "    elif hasattr(model, \"fc\"):\n",
    "        model.fc = NoAction()\n",
    "        out_channels = model(test_input).shape\n",
    "\n",
    "    elif hasattr(model, \"classifier\"):\n",
    "        model.classifier = NoAction()\n",
    "        out_channels = model(test_input).shape\n",
    "\n",
    "    print(f\"| [{creator.__name__}] | Size: [{num_params(model):,}] | Out: [{out_channels}] |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1024/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = models.resnet18()\n",
    "m.fc = NoAction()\n",
    "m.avgpool = NoAction()\n",
    "out = m(test_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 16, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10644/669044706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
