{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils.print as print_f\n",
    "\n",
    "from utils.coco_eval import get_eval_params_dict\n",
    "from utils.engine import xami_train_one_epoch, xami_evaluate, get_iou_types\n",
    "from utils.plot import plot_losses, plot_train_val_ap_ars, get_ap_ar_for_train_val\n",
    "from utils.save import get_data_from_metric_logger\n",
    "from utils.coco_utils import get_cocos\n",
    "\n",
    "from models.setup import ModelSetup\n",
    "from models.build import create_model_from_setup\n",
    "from models.train import TrainingInfo\n",
    "from utils.save import check_best, end_train\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from utils.eval import get_ar_ap\n",
    "from utils.train import get_optimiser, get_lr_scheduler, print_params_setup\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS, XAMI_MIMIC_PATH\n",
    "from  datetime import datetime\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n"
     ]
    }
   ],
   "source": [
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5410, -0.2934, -2.1788],\n",
       "        [ 0.5684, -1.0845, -1.3986]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.randn(2,3)\n",
    "\n",
    "# pytorch reproducibility work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## then we prepare the data. \n",
    "use_iobb = True\n",
    "io_type_str = \"IoBB\" if use_iobb else \"IoU\"\n",
    "labels_cols = DEFAULT_REFLACX_LABEL_COLS\n",
    "iou_thrs = np.array([0.5])\n",
    "\n",
    "\n",
    "model_setup =  ModelSetup(\n",
    "        name=\"CXR+Clinical\",\n",
    "        use_clinical=True,\n",
    "        use_custom_model=True,\n",
    "        use_early_stop_model=True,\n",
    "        best_ar_val_model_path=None,\n",
    "        best_ap_val_model_path=None,\n",
    "        final_model_path=None,\n",
    "        backbone=\"mobilenet_v3\",\n",
    "        optimiser=\"sgd\",\n",
    "        lr=1e-3,\n",
    "        # lr=1e-4,\n",
    "        # weight_decay=0.001,\n",
    "        weight_decay=0,\n",
    "        pretrained=True,\n",
    "        record_training_performance=True,\n",
    "        dataset_mode=\"unified\",\n",
    "        image_size=256,\n",
    "        backbone_out_channels=16,\n",
    "        batch_size=4,\n",
    "        warmup_epochs=0,\n",
    "        lr_scheduler=\"ReduceLROnPlateau\",\n",
    "        # lr_scheduler=None,\n",
    "        reduceLROnPlateau_factor=0.1,\n",
    "        reduceLROnPlateau_patience=5,\n",
    "        reduceLROnPlateau_full_stop=True,\n",
    "        multiStepLR_milestones=[30, 50, 70, 90],\n",
    "        multiStepLR_gamma=0.1,\n",
    "        representation_size=32,\n",
    "        mask_hidden_layers=256,\n",
    "        using_fpn=False,\n",
    "        use_mask=False,\n",
    "        clinical_expand_dropout_rate=0,\n",
    "        clinical_conv_dropout_rate=0,\n",
    "        clinical_input_channels=32,\n",
    "        clinical_num_len=9,\n",
    "        clinical_conv_channels=32,\n",
    "        fuse_conv_channels=32,\n",
    "        fuse_dropout_rate=0,\n",
    "        box_head_dropout_rate=0,\n",
    "        fuse_depth=4,\n",
    "        fusion_strategy=\"concat\",\n",
    "        fusion_residule=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Load custom model\n",
      "Using pretrained backbone. mobilenet_v3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultimodalMaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ConvNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(576, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (rpn): XAMIRegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(16, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(16, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): XAMIRoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): XAMITwoMLPHead(\n",
       "      (fc6): Sequential(\n",
       "        (0): Linear(in_features=784, out_features=32, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=False)\n",
       "      )\n",
       "      (fc7): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=32, out_features=6, bias=True)\n",
       "      (bbox_pred): Linear(in_features=32, out_features=24, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gender_emb_layer): Embedding(2, 23)\n",
       "  (clinical_expand_conv): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout2d(p=0, inplace=False)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout2d(p=0, inplace=False)\n",
       "    (8): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout2d(p=0, inplace=False)\n",
       "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Dropout2d(p=0, inplace=False)\n",
       "    (16): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): Dropout2d(p=0, inplace=False)\n",
       "    (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU()\n",
       "    (23): Dropout2d(p=0, inplace=False)\n",
       "    (24): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU()\n",
       "    (27): Dropout2d(p=0, inplace=False)\n",
       "    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU()\n",
       "    (31): Dropout2d(p=0, inplace=False)\n",
       "    (32): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (34): ReLU()\n",
       "    (35): Dropout2d(p=0, inplace=False)\n",
       "    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU()\n",
       "    (39): Dropout2d(p=0, inplace=False)\n",
       "    (40): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU()\n",
       "    (43): Dropout2d(p=0, inplace=False)\n",
       "    (44): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (45): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (46): ReLU()\n",
       "    (47): Dropout2d(p=0, inplace=False)\n",
       "    (48): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (50): ReLU()\n",
       "    (51): Dropout2d(p=0, inplace=False)\n",
       "    (52): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (53): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (54): ReLU()\n",
       "    (55): Dropout2d(p=0, inplace=False)\n",
       "    (56): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (57): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (58): ReLU()\n",
       "    (59): Dropout2d(p=0, inplace=False)\n",
       "    (60): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (61): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (clinical_convs): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout2d(p=0, inplace=False)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout2d(p=0, inplace=False)\n",
       "    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout2d(p=0, inplace=False)\n",
       "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Dropout2d(p=0, inplace=False)\n",
       "    (16): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fuse_convs): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout2d(p=0, inplace=False)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout2d(p=0, inplace=False)\n",
       "    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout2d(p=0, inplace=False)\n",
       "    (12): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Dropout2d(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.transforms import get_transform\n",
    "from data.datasets import ReflacxDataset, collate_fn\n",
    "from data.load import seed_worker, get_dataloader_g\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.coco_utils import get_coco_api_from_dataset\n",
    "\n",
    "################ Datasets ################\n",
    "dataset_params_dict = {\n",
    "    \"XAMI_MIMIC_PATH\": XAMI_MIMIC_PATH,\n",
    "    \"with_clinical\": model_setup.use_clinical,\n",
    "    \"dataset_mode\": model_setup.dataset_mode,\n",
    "    \"bbox_to_mask\": model_setup.use_mask,\n",
    "    \"labels_cols\": labels_cols,\n",
    "}\n",
    "\n",
    "train_dataset = ReflacxDataset(\n",
    "        **dataset_params_dict, split_str=\"train\", transforms=get_transform(train=True), \n",
    "    )\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=get_dataloader_g(0),\n",
    ")\n",
    "\n",
    "train_coco = get_coco_api_from_dataset(train_dataloader.dataset)\n",
    "\n",
    "eval_params_dict = get_eval_params_dict(\n",
    "    train_dataset, iou_thrs=iou_thrs, use_iobb=use_iobb,\n",
    ")\n",
    "\n",
    "############### Model ###############\n",
    "\n",
    "model = create_model_from_setup(\n",
    "    labels_cols,\n",
    "    model_setup,\n",
    "    rpn_nms_thresh=0.3,\n",
    "    box_detections_per_img=10,\n",
    "    box_nms_thresh=0.2,\n",
    "    rpn_score_thresh=0.0,\n",
    "    box_score_thresh=0.05,\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## then we check whether the dataloader laod the same data.\n",
    "data = next(iter(train_dataloader))\n",
    "data = train_dataset.prepare_input_from_data(data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([293], device='cuda:0')\n",
      "7c6edd07-7c4c8c3e-d8b216c7-88d2d002-975f90e3\n"
     ]
    }
   ],
   "source": [
    "print(data[-1][0]['image_id'])\n",
    "print(data[-1][0]['dicom_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the dataload correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# loss_dict, outputs = model(*data[:-1], targets=data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial model is correct.\n",
    "\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'loss_classifier': tensor(1.8194, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
    "#  'loss_box_reg': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>),\n",
    "#  'loss_objectness': tensor(0.6932, device='cuda:0',\n",
    "#         grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
    "#  'loss_rpn_box_reg': tensor(0.4562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)}\n",
    "\n",
    "\n",
    "# [{'boxes': tensor([[2.5204e+00, 1.0799e+00, 2.7798e+02, 1.0702e+02],\n",
    "#           [9.9822e+00, 4.4080e+00, 1.1009e+03, 4.3683e+02],\n",
    "#           [2.7997e+01, 2.5075e+01, 3.0560e+03, 2.4849e+03],\n",
    "#           [2.3693e+03, 1.1362e+03, 2.6742e+03, 1.4973e+03],\n",
    "#           [4.9516e+02, 9.4079e+02, 8.7172e+02, 1.5129e+03],\n",
    "#           [9.3348e+02, 9.3862e+02, 1.4424e+03, 1.6008e+03],\n",
    "#           [4.9111e+02, 9.4757e+02, 8.7426e+02, 1.5319e+03],\n",
    "#           [0.0000e+00, 1.1112e-01, 2.8200e+02, 1.1193e+02],\n",
    "#           [0.0000e+00, 4.5356e-01, 1.1169e+03, 4.5688e+02],\n",
    "#           [0.0000e+00, 2.5801e+00, 3.0560e+03, 2.5440e+03]], device='cuda:0',\n",
    "#          grad_fn=<StackBackward0>),\n",
    "#   'labels': tensor([4, 4, 4, 4, 4, 4, 3, 5, 5, 5], device='cuda:0'),\n",
    "#   'scores': tensor([0.1903, 0.1903, 0.1903, 0.1897, 0.1883, 0.1866, 0.1768, 0.1765, 0.1765,\n",
    "#           0.1765], device='cuda:0', grad_fn=<IndexBackward0>)},\n",
    "#  {'boxes': tensor([[2.8612e+00, 1.1996e+01, 2.3124e+02, 5.2541e+02],\n",
    "#           [1.5962e+01, 3.4023e+01, 1.2900e+03, 1.4902e+03],\n",
    "#           [0.0000e+00, 6.5438e-01, 2.3528e+02, 5.5139e+02],\n",
    "#           [0.0000e+00, 1.8560e+00, 1.3125e+03, 1.5639e+03],\n",
    "#           [1.9556e+00, 8.2432e+00, 2.3229e+02, 5.3670e+02],\n",
    "#           [1.0909e+01, 2.3380e+01, 1.2958e+03, 1.5222e+03],\n",
    "#           [0.0000e+00, 0.0000e+00, 2.2641e+02, 5.5311e+02],\n",
    "#           [0.0000e+00, 0.0000e+00, 1.2630e+03, 1.5688e+03],\n",
    "#           [0.0000e+00, 1.3181e+01, 2.3259e+02, 5.3898e+02],\n",
    "#           [0.0000e+00, 3.7384e+01, 1.2975e+03, 1.5287e+03]], device='cuda:0',\n",
    "#          grad_fn=<StackBackward0>),\n",
    "# ...\n",
    "#           [7.4653e+02, 1.4055e+03, 1.1647e+03, 1.8839e+03]], device='cuda:0',\n",
    "#          grad_fn=<StackBackward0>),\n",
    "#   'labels': tensor([4, 4, 4, 4, 3, 3, 3, 3, 5, 5], device='cuda:0'),\n",
    "#   'scores': tensor([0.1931, 0.1911, 0.1891, 0.1891, 0.1834, 0.1834, 0.1824, 0.1818, 0.1684,\n",
    "#           0.1673], device='cu da:0', grad_fn=<IndexBackward0>)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_loss_weight = None\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "if dynamic_loss_weight:\n",
    "    params += [p for p in dynamic_loss_weight.parameters() if p.requires_grad]\n",
    "\n",
    "iou_types = get_iou_types(model, model_setup)\n",
    "optimizer = torch.optim.SGD(\n",
    "            params,\n",
    "            lr=torch.tensor(0.01)\n",
    "\n",
    "            \n",
    "        )\n",
    "lr_scheduler = get_lr_scheduler(optimizer, model_setup)\n",
    "\n",
    "# train_evaluator, train_loger = xami_train_one_epoch(\n",
    "#     model=model,\n",
    "#     optimizer=optimizer,\n",
    "#     data_loader=train_dataloader,\n",
    "#     device=device,\n",
    "#     epoch=0,\n",
    "#     print_freq=10,\n",
    "#     iou_types=iou_types,\n",
    "#     coco=train_coco,\n",
    "#     score_thres=None,\n",
    "#     evaluate_on_run=True,\n",
    "#     params_dict=eval_params_dict,\n",
    "#     dynamic_loss_weight=dynamic_loss_weight,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.param_groups[0]['lr'].item()\n",
    "# #0.009999999776482582"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# loss_dict, outputs = model(*data[:-1], targets=data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_multiplier(loss_dict):\n",
    "    loss_dict[\"loss_classifier\"] *= 10\n",
    "    loss_dict[\"loss_box_reg\"] *= 5\n",
    "\n",
    "    loss_dict[\"loss_objectness\"] *= 1e-5\n",
    "    loss_dict[\"loss_rpn_box_reg\"] *= 1e-5\n",
    "\n",
    "    return loss_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.cuda.amp.autocast(enabled=False):\n",
    "#         loss_dict, outputs = model(*data[:-1], targets=data[-1])\n",
    "#         loss_dict = loss_multiplier(loss_dict)\n",
    "\n",
    "#         if dynamic_loss_weight:\n",
    "#             # loss_dict[\"loss_objectness\"] *= 4\n",
    "#             # loss_dict[\"loss_rpn_box_reg\"] *= 2\n",
    "#             losses = dynamic_loss_weight(loss_dict)\n",
    "#         else:\n",
    "#             losses = sum(loss for loss in loss_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor(18.3728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
    "# tensor(18.3728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.zero_grad()\n",
    "# losses.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import detect_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(train_dataloader):\n",
    "#     if i==0:\n",
    "#         first_data = data\n",
    "#     elif i == 1:\n",
    "#         second_data = data\n",
    "#     else:\n",
    "#         raise StopIteration()\n",
    "\n",
    "# [target['dicom_id'] for target in first_data[-1]]\n",
    "\n",
    "# ['4f3b79f0-4c4d27f8-23240d1e-515d66ca-6fde3e41',\n",
    "#  '4a629500-9c3281ca-90bab490-9b6ac9c1-e5e6a580',\n",
    "#  'a586a4ad-997f80a9-38bbdd65-cb92a6cc-51c8520e',\n",
    "#  'a5264d2c-5d74521a-9fc6b28a-4991fbd0-ad4c15d1']\n",
    "\n",
    "\n",
    "# [target['dicom_id'] for target in second_data[-1]]\n",
    "## the dataset is checked.\n",
    "\n",
    "# ['4f4218c0-7e3de34f-abade5db-964b2d47-addcc964',\n",
    "#  'b967d8e3-c164811b-04ff781e-85201e77-94f258ef',\n",
    "#  '4de3b906-58b53e1d-27ad92d5-ca85ff56-83cffd81',\n",
    "#  '1ffc255f-2064c19a-a5cfad02-c22fa939-5db5f9c1']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iter 0====================\n",
      "tensor(18.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18.51391808342778\n",
      "tensor([[ 0.0113,  0.0396, -0.0356],\n",
      "        [ 0.0101, -0.0355, -0.0446],\n",
      "        [-0.0054,  0.0215,  0.0006]], device='cuda:0')\n",
      "0.011276589760136277\n",
      "tensor([[-0.0270, -0.1334, -0.1873],\n",
      "        [-0.1515, -0.1765, -0.1383],\n",
      "        [-0.0960, -0.0688, -0.0258]], device='cuda:0')\n",
      "-0.02701888356451491\n",
      "====================Iter 1====================\n",
      "tensor(16.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16.499612341058622\n",
      "tensor([[ 0.0115,  0.0410, -0.0337],\n",
      "        [ 0.0116, -0.0337, -0.0432],\n",
      "        [-0.0045,  0.0222,  0.0009]], device='cuda:0')\n",
      "0.011546778595781427\n",
      "tensor([[-0.0706, -0.0488, -0.1707],\n",
      "        [-0.3516, -0.0866,  0.0581],\n",
      "        [-0.0635, -0.0512,  0.0034]], device='cuda:0')\n",
      "-0.07057392702294056\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9304/1317312687.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m#18.0247\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "# if epoch == 1:\n",
    "#     print(\"start wariming up \")\n",
    "#     warmup_factor = 1.0 / 1000\n",
    "#     warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "#     lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "#         optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    "#     )\n",
    "\n",
    "for i, data in enumerate(train_dataloader):\n",
    "    data = train_dataloader.dataset.prepare_input_from_data(data, device)\n",
    "    with torch.cuda.amp.autocast(enabled=False, dtype=torch.float32):\n",
    "        loss_dict, outputs = model(*data[:-1], targets=data[-1])\n",
    "        loss_dict = loss_multiplier(loss_dict)\n",
    "\n",
    "        if dynamic_loss_weight: \n",
    "            # loss_dict[\"loss_objectness\"] *= 4\n",
    "            # loss_dict[\"loss_rpn_box_reg\"] *= 2\n",
    "            losses = dynamic_loss_weight(loss_dict)\n",
    "        else:\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "\n",
    "    print_f.print_title(f\"Iter {i}\")\n",
    "    print(losses)\n",
    "    print(losses.item())\n",
    "\n",
    "\n",
    "    print(model.fuse_convs[0].weight.data[0][0])\n",
    "    print(model.fuse_convs[0].weight.data[0][0][0][0].item())\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    losses.backward()\n",
    "    \n",
    "    print(model.fuse_convs[0].weight.grad[0][0])\n",
    "    print(model.fuse_convs[0].weight.grad[0][0][0][0].item())\n",
    "\n",
    "    # the gradient is not the same.\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if i >= 1:\n",
    "        raise StopIteration()\n",
    "\n",
    "#18.0247\n",
    "#18.0230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0155, -0.0358, -0.0260],\n",
      "        [ 0.0014,  0.0559, -0.0069],\n",
      "        [ 0.0526, -0.0463,  0.0237]], device='cuda:0')\n",
      "0.01546361856162548\n"
     ]
    }
   ],
   "source": [
    "# print(model.fuse_convs[0].weight.data[0][0])\n",
    "# print(model.fuse_convs[0].weight.data[0][0][0][0].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_37764/2324737213.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "losses.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24338267743587494"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fuse_convs[0].weight.grad[0][0][0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16100/2895586925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0365, -0.0433, -0.0091],\n",
       "        [-0.0491,  0.0281, -0.0107],\n",
       "        [ 0.0365, -0.0679, -0.0029]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the weight are updated to the same.\n",
    "model.fuse_convs[0].weight.data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it's different, it caused by the optimization process.\n",
    "\n",
    "# tensor([[ 0.0134, -0.0374, -0.0271],\n",
    "#         [-0.0006,  0.0555, -0.0072],\n",
    "#         [ 0.0528, -0.0461,  0.0255]], device='cuda:0')\n",
    "\n",
    "\n",
    "# tensor([[ 0.0134, -0.0374, -0.0271],\n",
    "#         [-0.0006,  0.0555, -0.0072],\n",
    "#         [ 0.0528, -0.0461,  0.0255]], device='cuda:0')\n",
    "\n",
    "\n",
    "## updated differently using train_one_epoch\n",
    "\n",
    "# tensor([[-0.0365, -0.0433, -0.0091],\n",
    "#         [-0.0491,  0.0281, -0.0107],\n",
    "#         [ 0.0365, -0.0679, -0.0029]], device='cuda:0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5078463399602832 0.1031347743811897\n"
     ]
    }
   ],
   "source": [
    "train_ar, train_ap = get_ar_ap(train_evaluator)\n",
    "print(train_ar, train_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0010000000474974513,\n",
       " 'loss': 3.6032652854919434,\n",
       " 'loss_classifier': 3.570329189300537,\n",
       " 'loss_box_reg': 0.03292705863714218,\n",
       " 'loss_objectness': 6.931795269338181e-06,\n",
       " 'loss_rpn_box_reg': 2.338313151994953e-06}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_from_metric_logger(train_loger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "## it's inside xami_train_one_epoch\n",
    "\n",
    "# 0.5061725923301151, 0.09079530820259449\n",
    "\n",
    "# {'lr': 0.0010000000474974513,\n",
    "#  'loss': 3.5543720722198486,\n",
    "#  'loss_classifier': 3.5296542644500732,\n",
    "#  'loss_box_reg': 0.02470848336815834,\n",
    "#  'loss_objectness': 6.9316301960498095e-06,\n",
    "#  'loss_rpn_box_reg': 2.338271542612347e-06}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we move it out to test which part is wrong.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
